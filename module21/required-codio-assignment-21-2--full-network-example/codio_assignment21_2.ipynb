{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "289176f1e9ee2134859171aa4bc36886",
     "grade": false,
     "grade_id": "cell-9ba7ab811a68c1dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Required Codio Assignment 21.2: Full Network Example\n",
    "\n",
    "**Expected Time = 60 minutes**\n",
    "\n",
    "**Total Points = 30**\n",
    "\n",
    "This activity focuses on using the full Titanic dataset and remaining features with a single layered neural network.  In the last example with only two features an accuracy of roughly 65% was achieved.  Using more features and a similar network architecture you will that the model improves. \n",
    "\n",
    "#### Index \n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "af4cae572474750f77f2f7c804eb7189",
     "grade": false,
     "grade_id": "cell-1eba63ea4cbb59f0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### The Data\n",
    "\n",
    "Below the titanic data is again loaded.  For this exercise you will use the columns `['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class']` as the features for predicting the column `survived`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic.loc[:, ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class']]\n",
    "y = titanic['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   pclass    891 non-null    int64   \n",
      " 1   sex       891 non-null    object  \n",
      " 2   age       714 non-null    float64 \n",
      " 3   sibsp     891 non-null    int64   \n",
      " 4   parch     891 non-null    int64   \n",
      " 5   fare      891 non-null    float64 \n",
      " 6   embarked  889 non-null    object  \n",
      " 7   class     891 non-null    category\n",
      "dtypes: category(1), float64(2), int64(3), object(2)\n",
      "memory usage: 49.9+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83bb795227456429bf840dcaec98007d",
     "grade": false,
     "grade_id": "cell-c151216974ebbaec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Preparing the features\n",
    "\n",
    "**10 points**\n",
    "\n",
    "Begin by first filling the missing values inside the `age` columns with the mean of that column.\n",
    "\n",
    "Next, use the `make_column_transformer` function to prepare the features.  Use `OneHotEncoder` with `drop = 'if_binary'` on all categorical features. Use the `StandardScaler` on the remaining features. Assign the transformation to `t` below.\n",
    "\n",
    "Finally, use the `fit_transform` function on `t` with argument equal to `X` to transfomf the data and assign the result to `X_t` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e137638cf6b9601367a6092f064913c",
     "grade": false,
     "grade_id": "cell-537339f5cc20a045",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "X_t = ''\n",
    "\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Fill missing age values with mean\n",
    "X['age'] = X['age'].fillna(X['age'].mean())\n",
    "\n",
    "# Create column transformer\n",
    "categorical_features = ['sex', 'embarked', 'class']\n",
    "numerical_features = ['pclass', 'age', 'sibsp', 'parch', 'fare']\n",
    "\n",
    "t = make_column_transformer(\n",
    "    (OneHotEncoder(drop='if_binary'), categorical_features),\n",
    "    (StandardScaler(), numerical_features)\n",
    ")\n",
    "\n",
    "# Transform the data\n",
    "X_t = t.fit_transform(X)\n",
    "\n",
    "### ANSWER CHECK\n",
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bd8c5f2f5f6d2d7553bd3fb2b5b7b21",
     "grade": true,
     "grade_id": "cell-9c455d637c5f8658",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cdf5b4475fc9bd5173a04cc10b742035",
     "grade": false,
     "grade_id": "cell-fc26afdc54491cc0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### The Network Architecture\n",
    "\n",
    "**10 points**\n",
    "\n",
    "Below, construct a sequantial network named `model` with one hidden layer with 100 dense units and a `relu` activation function.  The output layer of this model should have one node and should be using the `sigmoid` activation function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b21985300d70a9960f02924c882394d6",
     "grade": false,
     "grade_id": "cell-c56c772a18ea7232",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x105c8c160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "tf.random.set_seed(42)\n",
    "model = ''\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "tf.random.set_seed(42)\n",
    "model = Sequential([\n",
    "    Dense(100, activation='relu', input_shape=(X_t.shape[1],)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "### ANSWER CHECK\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6ac47df427d4aad6ee36795d248821b",
     "grade": true,
     "grade_id": "cell-9c5bd1cdd35a6125",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "79edc8bdbf805d9e6d683660c1c3ad7e",
     "grade": false,
     "grade_id": "cell-0d6c40f92b8f37f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Train and Evaluate the Network\n",
    "\n",
    "**10 points**\n",
    "\n",
    "Finally, train and evaluate the network using the following compilation settings.  Assign the fit model to `history` below.\n",
    "\n",
    "- `optimizer = 'rmsprop'`\n",
    "- `loss = 'bce'`\n",
    "- `metrics = ['accuracy']`\n",
    "- `epochs = 20`\n",
    "- `batch_size = 10`\n",
    "- `verbose = 0`\n",
    "\n",
    "Also, be sure to leave the `tf.random.set_seed(42)` for proper grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "087732e6123423b5ccf32e75b020810c",
     "grade": false,
     "grade_id": "cell-d0ef12fa2d67be00",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8406285047531128"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "history = ''\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "tf.random.set_seed(42)\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_t, y,\n",
    "                   epochs=20,\n",
    "                   batch_size=10,\n",
    "                   verbose=0)\n",
    "\n",
    "### ANSWER CHECK\n",
    "history.history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Exercises\n",
    "\n",
    "This notebook demonstrated building a neural network for the Titanic survival prediction problem using multiple features. The exercise was broken down into three main parts:\n",
    "\n",
    "1. **Data Preparation**\n",
    "   - Used more features compared to previous examples: 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class'\n",
    "   - Handled missing values in the age column using mean imputation\n",
    "   - Applied feature preprocessing using column transformer:\n",
    "     - OneHotEncoder for categorical features\n",
    "     - StandardScaler for numerical features\n",
    "\n",
    "2. **Network Architecture**\n",
    "   - Built a simple sequential model with:\n",
    "     - One hidden layer (100 units with ReLU activation)\n",
    "     - Output layer (1 unit with sigmoid activation)\n",
    "   - Input shape adapted to handle 13 features after preprocessing\n",
    "\n",
    "3. **Model Training**\n",
    "   - Compiled model with RMSprop optimizer and binary cross-entropy loss\n",
    "   - Trained for 20 epochs with batch size of 10\n",
    "   - Achieved approximately 84% accuracy on the full dataset\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- Using more features improved the model's performance compared to the previous example (from 65% to 84% accuracy)\n",
    "- Proper feature preprocessing is crucial:\n",
    "  - Categorical features need to be one-hot encoded\n",
    "  - Numerical features benefit from standardization\n",
    "- Even a simple neural network architecture can achieve good results with well-prepared data\n",
    "- The combination of appropriate feature engineering and neural network design can significantly impact model performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codio_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
