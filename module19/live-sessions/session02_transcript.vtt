WEBVTT

1
00:00:00.620 --> 00:00:10.290
Vikesh K: And we have okay, we have more folks as well. Hello, welcome everyone. Shakhar, Vikash, Namurta, Matt.

2
00:00:10.850 --> 00:00:24.289
Vikesh K: Okay, lovely. So coming to the question, which is I believe there was a one ideal solution set which was prepared. And again, that was taken from a previous student. But I think

3
00:00:24.400 --> 00:00:33.302
Vikesh K: maybe it's introduced later or you know, shown later. I'm not sure when when that will be done. But right now.

4
00:00:33.850 --> 00:00:42.959
Vikesh K: you know we don't really encourage to people to change exchange solutions primarily, because some people, some of you, have done it, and some of you don't.

5
00:00:43.355 --> 00:00:43.750
Kiran: Yeah.

6
00:00:44.000 --> 00:00:50.529
Vikesh K: So this will be unfair. It's like unfair to people who haven't done it. Oh, sorry to have done it, and submitted.

7
00:00:50.530 --> 00:00:53.761
Kiran: Not now. Maybe maybe after the course is completed,

8
00:00:54.120 --> 00:00:59.139
Vikesh K: Oh, yeah, yeah, I think I think I I will again check with the team. I can check with that team.

9
00:00:59.510 --> 00:01:03.279
Vikesh K: and you know. Remind them. You know, we used to do that.

10
00:01:03.480 --> 00:01:13.860
Vikesh K: Maybe we or we can. What we can do is individually submit it or show it to the learners who have completed, and I'm not sure if there is any automated way to do that.

11
00:01:14.140 --> 00:01:18.870
Vikesh K: But that could be another way. So only those of you have submitted will get a sort of a solution

12
00:01:19.460 --> 00:01:22.029
Vikesh K: sample thing to compare.

13
00:01:22.780 --> 00:01:27.190
Vikesh K: All right. So that cool. That's a good point.

14
00:01:27.310 --> 00:01:34.950
Vikesh K: all right. So this week we the focus is on recommendations. Right? Recommendation is a niche topic.

15
00:01:36.330 --> 00:01:53.950
Vikesh K: They, you know, Andrew Wing is very famous for saying a recommendation is done better at the companies rather than in an academia, because in academia they didn't have that kind of data to really work on recommendations. But for commercial purposes, recommendations become

16
00:01:54.000 --> 00:02:07.050
Vikesh K: very important. So, for example, Amazon, Amazon, it said, market research, I don't think Amazon themselves have put out the numbers, but roughly, 30% of their sale comes from recommendation.

17
00:02:07.330 --> 00:02:12.279
Vikesh K: And if you think about it, this happening at an Amazon scale, it's a huge thing.

18
00:02:12.840 --> 00:02:33.137
Vikesh K: And Amazon recommendations are pretty pretty good. So, for example, let's say, if I like some book, and I have read it, and what I do, I often put that book's name in Amazon. I check for the book recommendation, because if I've liked that book, most likely I will like the other books which Amazon recommends. So that's 1 way. How I you know

19
00:02:33.780 --> 00:02:37.959
Vikesh K: generate my reading list through Amazon. So Amazon is very, very good at that.

20
00:02:38.802 --> 00:02:44.620
Vikesh K: So so this is more of an industry topic. All of us do that. For example, we.

21
00:02:45.520 --> 00:02:48.540
Vikesh K: I work but

22
00:02:48.690 --> 00:03:04.650
Vikesh K: learn in this course is more or less one or 2 methods of that. And I thought, I will give you. We will go through 2 examples just to understand that further, and, you know, go through it. But before I talk about the stuff which is covered in the course. I thought, I will give you one

23
00:03:05.130 --> 00:03:09.309
Vikesh K: one easy one, not not easy, but at least slightly interesting one.

24
00:03:10.080 --> 00:03:26.740
Vikesh K: I've I've made this in chat. Gpt. See how the chat gpt thing looks like. So at least it I thought just to spice it up so I I don't remember the prompt which I put in, but it generated this image for me. It's yeah, as you can see, it's still not very good. It's bit messy and all.

25
00:03:27.110 --> 00:03:30.909
Vikesh K: But yeah, hopefully, with passage of time, it will improve.

26
00:03:31.650 --> 00:03:38.579
Vikesh K: Okay, so this data set the 1st technique which I'm going to use right now, which I wanted to show you is more of a

27
00:03:38.790 --> 00:03:44.239
Vikesh K: in a way, a distance based measure. And that's what I wanted to show to you. All right.

28
00:03:45.100 --> 00:03:48.939
Vikesh K: So, for example, you have K nearest neighbor.

29
00:03:49.330 --> 00:03:58.580
Vikesh K: and then there is another version of it which is in which you remove the like. This is a supervised version. But you also have an unsupervised version of it.

30
00:03:58.800 --> 00:04:04.852
Vikesh K: And that's what I'm gonna use. Because if you think about it clustering in a way,

31
00:04:05.500 --> 00:04:10.219
Vikesh K: is a kind of recommendation system. So let's say, if you have 10 songs

32
00:04:10.380 --> 00:04:13.520
Vikesh K: and you divide them into 3 groups. All right.

33
00:04:13.640 --> 00:04:17.079
Vikesh K: So let's say 2 songs here.

34
00:04:17.757 --> 00:04:29.219
Vikesh K: Maybe 4 songs here. So that's 6. And then 4 pending songs in this group. All right. So now let's say, you know. So she's a fan of this song. Okay, whatever that song be.

35
00:04:29.820 --> 00:04:34.430
Vikesh K: And I want to recommend more songs to him. Then the best scenario is.

36
00:04:34.570 --> 00:04:37.549
Vikesh K: I will recommend him these 3 songs.

37
00:04:37.830 --> 00:04:53.090
Vikesh K: Okay, which has, which are closest to it. Yeah. So that's that's how at least you can do it in clustering. The other thing you can do is which which I'm gonna so this is the clustering version. Now, what I'm going to do is the distance based version that way is that

38
00:04:53.290 --> 00:05:15.227
Vikesh K: I will measure the distance of this song across all the songs. How far songs are from each other? Then the let's say so, she says, give me top 5 recommendations. Then I will choose the top 5 songs which are closest to it, and give the recommendations alright. That could be so. One was a pure clustering. You 1st divide it into groups, the second

39
00:05:15.820 --> 00:05:34.410
Vikesh K: but on the same concept is, I will do it on the basis of distance. Okay, this is, this is a sort of a simple method in this. You don't really right. Now, you're not taking any user inputs. But this is just on the properties of that song. Okay, as I will show you. And this is one example I believe I've shown previously.

40
00:05:34.770 --> 00:05:36.909
Vikesh K: and this is from spotify.

41
00:05:38.060 --> 00:05:39.910
Vikesh K: So if you look at this.

42
00:05:40.030 --> 00:05:41.520
Vikesh K: This is what you have.

43
00:05:41.700 --> 00:05:47.599
Vikesh K: You have different components of a song which is, let's say, speechiness, tempo balance. Here

44
00:05:47.770 --> 00:05:54.430
Vikesh K: liveness, loudness, instrumentalness. Okay. So for each song you have multiple parameters.

45
00:05:55.180 --> 00:05:57.950
Vikesh K: And how do you choose

46
00:05:58.706 --> 00:06:04.390
Vikesh K: songs? Let's say you like this particular song right the 1st row

47
00:06:04.690 --> 00:06:20.719
Vikesh K: you prefer this sound, and then what the algorithm will do is find the other points which are closest to it, based on the all the other parameters, and give you a recommendation. Okay, so that's what this whole Jupyter notebook is about.

48
00:06:21.650 --> 00:06:24.640
Vikesh K: I wanted you to

49
00:06:25.020 --> 00:06:38.529
Vikesh K: get a hang of it. So that's why I prepared it. I'm I'm not. Gonna go into the details of the whole code, which I think maybe you can consume later on. But essentially, I'm just doing 1st prepping part. And remember now again, because this is a

50
00:06:39.630 --> 00:06:45.480
Vikesh K: one second. Yes, this is a distance based algorithm. You know, you're calculating

51
00:06:47.260 --> 00:06:52.369
Vikesh K: how points are far from each other. So let's say you have only 2 points.

52
00:06:52.500 --> 00:06:54.530
Vikesh K: And this is on energy.

53
00:06:54.640 --> 00:06:56.699
Vikesh K: Okay, let's say energy.

54
00:06:57.110 --> 00:07:06.870
Vikesh K: And then let's say you have duration milliseconds. All right? So what you're gonna do for each song, let's say you identify a song. And this is the id of the song. Here

55
00:07:07.610 --> 00:07:13.799
Vikesh K: you will measure its distance to other points based on these 2 parameters. All right.

56
00:07:14.110 --> 00:07:25.689
Vikesh K: Only thing what we are doing. I'm taking all the numerical values here, and since I'm going to use distance. It's important that all of them should be on the same scale, because you know what will happen otherwise

57
00:07:25.790 --> 00:07:37.370
Vikesh K: if you focus on duration and energy. As you can see, this is on a very 2 different scales. Duration will heavily dominate, and you don't want that. You want each of these

58
00:07:37.500 --> 00:07:46.440
Vikesh K: columns to have and sort of an equal, say right? And to do that, you need to standardize. So remember, whenever we have any distance based algorithm.

59
00:07:46.640 --> 00:07:50.299
Vikesh K: the 1st step you would need to do is standardize so.

60
00:07:51.450 --> 00:07:59.550
Vikesh K: and you will see I'm doing the whole standardization in one. Go because there is no train test set here as such. All right. And this is.

61
00:07:59.740 --> 00:08:08.429
Vikesh K: if you think about it. This is not exactly a machine learning algorithm. This is just measuring the distance and trying to show you which points are closer and far off.

62
00:08:08.750 --> 00:08:09.830
Vikesh K: So

63
00:08:11.130 --> 00:08:17.800
Vikesh K: let me highlight this. If you have any questions, let me know, because maybe I'm going a little too fast.

64
00:08:18.200 --> 00:08:22.339
Vikesh K: But but this is how the data points look like

65
00:08:22.500 --> 00:08:29.280
Vikesh K: without any scaling. All right, as you can see, only duration milliseconds dominates because that.

66
00:08:30.400 --> 00:08:41.289
Vikesh K: That is a big one. But after the scaling hopefully, and it's taking some time you should be able to better see the other data points alright, because when you bring them

67
00:08:41.419 --> 00:08:45.189
Vikesh K: all of them on the same scale that highlights the main things.

68
00:08:46.190 --> 00:08:57.020
Vikesh K: And this is the Eligo, which is again in scikit-learn. This is what we are going to use. And so this is like they have mentioned. This is an unsupervised learner for implementing. Neighbor searches

69
00:08:57.270 --> 00:08:57.996
Vikesh K: all right

70
00:08:59.450 --> 00:09:07.100
Vikesh K: you can. By the way, you can specify how many neighbors you want to search for. So what it does is. Let's say

71
00:09:07.770 --> 00:09:09.310
Vikesh K: I like one song

72
00:09:10.180 --> 00:09:19.769
Vikesh K: what you can. And then, by default, it's 5. What it does. The algorithm allows you to get the 5 closest points to this song. Alright.

73
00:09:20.230 --> 00:09:23.890
Vikesh K: So, okay, I'm sorry. This is taking a lot of time.

74
00:09:24.270 --> 00:09:26.149
Vikesh K: So, but the main thing is.

75
00:09:26.350 --> 00:09:30.050
Vikesh K: I'm gonna implement this song, fit it.

76
00:09:30.280 --> 00:09:33.450
Vikesh K: And then this is the a simple demo of this.

77
00:09:34.120 --> 00:09:39.230
Vikesh K: Okay? And since this is unsupervised, there was no really trainer testing which I did here.

78
00:09:40.560 --> 00:09:46.100
Vikesh K: But this is an example. Part of this. Let's I might. I think we might have to wait for a while

79
00:09:46.970 --> 00:09:48.069
Vikesh K: for this to run.

80
00:09:48.200 --> 00:09:49.640
Vikesh K: It's a big data set.

81
00:09:53.020 --> 00:10:00.330
Vikesh K: but all of you got the hang of it. The at least the main idea of what we are trying to do so essentially, what we are using here is the distances

82
00:10:01.077 --> 00:10:11.360
Vikesh K: a very simple way to make a recommendation system. Okay, if let's say you like jazz or something. So, and the

83
00:10:11.480 --> 00:10:22.790
Vikesh K: jazz songs would have a certain kind of parameters about, you know, speechiness or energy. So all the songs which are similar to that jazz song will be your recommendation all right.

84
00:10:29.950 --> 00:10:32.000
Vikesh K: This is normal plot.

85
00:10:32.800 --> 00:10:34.890
Vikesh K: Okay, this is a scale one.

86
00:10:37.720 --> 00:10:39.430
Vikesh K: I think this wasn't required

87
00:10:43.920 --> 00:10:45.940
Vikesh K: last shot, and then we will see.

88
00:10:46.810 --> 00:10:48.429
Vikesh K: We'll move to the modeling part.

89
00:10:49.070 --> 00:10:51.230
Vikesh K: But I will show you. I wanted to

90
00:10:52.270 --> 00:11:02.239
Vikesh K: focus why on why I chose this particular data set. I wanted to show you one more thing. So once the whole thing is done, I will show you the other part of it hopefully. That will give you

91
00:11:03.150 --> 00:11:06.730
Vikesh K: some excitement about how this can be used further.

92
00:11:07.910 --> 00:11:10.730
Vikesh K: primarily, because this is a spotify data set. That's why

93
00:11:12.040 --> 00:11:15.106
Vikesh K: and spotify. Has some cool things going on

94
00:11:16.270 --> 00:11:20.708
Vikesh K: with the terms of you know how they classify a song? Let's see.

95
00:11:23.630 --> 00:11:30.520
Vikesh K: all of you are very silent. Is it making sense? Are you getting bored? Sorry. This is taking too much time. Maybe I should have.

96
00:11:31.550 --> 00:11:33.069
shashi: Yeah, that makes sense. I mean.

97
00:11:33.880 --> 00:11:39.560
Vikesh K: Okay, cool. So yeah, this is a much simpler idea compared to what you have. You know.

98
00:11:39.560 --> 00:11:40.619
shashi: Completed, now.

99
00:11:41.180 --> 00:11:42.400
Vikesh K: Okay, lovely.

100
00:11:44.150 --> 00:11:58.359
Vikesh K: The chart still is taking time. But at least okay. Maybe the other things have fitted. I just wanted to show you okay while it comes. So what I'm doing, I fit the model all right. And then let's say what I did. I selected a particular song.

101
00:11:58.790 --> 00:12:03.680
Vikesh K: and for that song.

102
00:12:04.250 --> 00:12:11.830
Vikesh K: I am getting the recommendations. Okay, you you can go through the code. Maybe I will add more comments, so that everything is easy to understand.

103
00:12:11.960 --> 00:12:14.900
Vikesh K: But then I'm using that song

104
00:12:15.150 --> 00:12:24.749
Vikesh K: scaled song. All right. I selected the song. Obviously you have to again scale it back. That's why I'm scaling it. And then I'm using that to get recommendations all right.

105
00:12:24.990 --> 00:12:26.260
Vikesh K: And

106
00:12:26.800 --> 00:12:33.119
Vikesh K: this is the stuff which I'm doing here. Okay, okay, I believe that part is still running. Let me stop this.

107
00:12:38.460 --> 00:12:45.679
Zhujun Wang: A quick question, so so for calculate the distance is calculated. The Euclidean distance, or.

108
00:12:45.860 --> 00:12:46.610
Vikesh K: Yes, yes.

109
00:12:46.610 --> 00:12:47.230
Zhujun Wang: Oh, okay.

110
00:12:47.910 --> 00:12:54.049
Vikesh K: Yeah. So I think, let's check that. What's the default? One.

111
00:12:57.750 --> 00:13:04.450
Vikesh K: Okay, since I haven't changed, it would be minkow whiskey, and I think by default.

112
00:13:06.580 --> 00:13:11.550
Vikesh K: Metric is standard. Okay? And

113
00:13:16.000 --> 00:13:18.459
Vikesh K: why the documentation so complicated.

114
00:13:18.940 --> 00:13:25.884
Vikesh K: they say, which is, when P equals to 2. But P. Oh, P. Is 2. Yes, Euclidean. Correct? Yeah.

115
00:13:26.250 --> 00:13:26.630
Zhujun Wang: Okay.

116
00:13:26.630 --> 00:13:34.160
Vikesh K: That's how they they broke it in 2 parts. Okay? So they use the Minkowski. And then obviously, then, when P is 2, it's it's Euclidean.

117
00:13:34.850 --> 00:13:40.359
Vikesh K: Alright. So what it does. Now I, this is giving me

118
00:13:40.980 --> 00:13:47.439
Vikesh K: all the locations of the other songs. Alright. And I can use that location.

119
00:13:50.130 --> 00:13:52.270
Vikesh K: Okay, to get the song names.

120
00:13:53.080 --> 00:14:17.390
Vikesh K: Okay? So this is very simple idea. You take a song, you see the numerical properties of it. And therefore in this case the speech in is the energy, and then you find the song which are closer to it. And now one interesting thing which is there is, I'm getting the name and the Id. Now the Id is interesting because this is a spotify data. So you can use this. And that's what I'm trying to do here is.

121
00:14:18.490 --> 00:14:27.199
Vikesh K: you will see with this Id. If you add this simple generic thing at the start, you can actually get a song. URL,

122
00:14:27.430 --> 00:14:31.820
Vikesh K: all right, and you will see this is still in this weird format.

123
00:14:32.080 --> 00:14:36.319
Vikesh K: Alright you need to highlight the HTML for that. You need to

124
00:14:36.570 --> 00:14:40.360
Vikesh K: use this to make the link dynamic. So once you click on it.

125
00:14:41.556 --> 00:14:43.280
Vikesh K: It will take you to the song.

126
00:14:44.200 --> 00:14:45.660
Vikesh K: Alright. So.

127
00:14:46.150 --> 00:15:02.810
Vikesh K: okay, yeah. So this is working. So that's the good thing. So if you make a recommendation thing with spotify, and especially if you have the Id on, then you can actually make this live connection thing. So what I did. And then I had this model. I dumped this

128
00:15:03.030 --> 00:15:13.980
Vikesh K: as a pickle file. And I'm I'm using this in the streamlit code, okay? And which I wanted to show. So this is one simple app which I created for this.

129
00:15:15.640 --> 00:15:40.699
Vikesh K: And I'm sharing it with all of you. So now, what happens how this thing works is. First, st let's say you set some parameters all right. You want a minimum level of acousticness energy, you know, depending on. Let's say, maybe you you know very you know you're expert in songs, and you know all what all these parameters mean, and then you select some parameters. So once you do that, it will tell you

130
00:15:40.810 --> 00:15:56.269
Vikesh K: unique songs in the data set which match the book criteria. Okay, right? Spelling is wrong. But, as you see, if I change it here, this will change. Okay, so what you are setting at the initial stages is some criteria. So once you have the criteria.

131
00:15:56.510 --> 00:15:58.600
Vikesh K: This is your song list.

132
00:15:59.070 --> 00:16:04.679
Vikesh K: So you select any song, and then the recommendations will change at the bottom.

133
00:16:04.890 --> 00:16:19.449
Vikesh K: All right. So let's say, woman, this is some song I have no clue, and then this is that song and the 3 or I've said, I think I believe 3 more recommendations which are similar to this song, all right. So you click on it

134
00:16:19.570 --> 00:16:23.059
Vikesh K: and it will straight away. Take you to the spotify page.

135
00:16:24.740 --> 00:16:32.210
Vikesh K: Cool so very easy. It's not very difficult. So the main thing which I did here is I,

136
00:16:32.480 --> 00:16:42.509
Vikesh K: oh, in this one, I that the the algorithm, the distances that it learned.

137
00:16:42.690 --> 00:16:48.720
Vikesh K: it's saved in that. And then, neighbors file all right. Sorry. Where is that?

138
00:16:49.370 --> 00:16:58.710
Vikesh K: So after learning so this, when you fit the model and right, so the the values get embedded in it, and you can export it as a pickle file.

139
00:16:58.820 --> 00:17:04.400
Vikesh K: This pickle file can be embedded in a streamlit code, and then you can make it dynamic.

140
00:17:05.160 --> 00:17:07.499
Vikesh K: Alright, and that's what I've done here.

141
00:17:08.990 --> 00:17:12.469
Vikesh K: Make sense. So this I also wanted to show you.

142
00:17:12.730 --> 00:17:18.030
Vikesh K: Let's say some of you are working on some capstone project, and maybe in for a predictions. Right?

143
00:17:18.400 --> 00:17:26.660
Vikesh K: You can have a streamlit code for it as well like a streamlined version for it as well. That will be very cool if you manage to do that. So along with your Github.

144
00:17:27.410 --> 00:17:31.870
Vikesh K: especially those of you looking for Job and all. Maybe this is a very cool way to show

145
00:17:32.790 --> 00:17:35.699
Vikesh K: all right any questions or doubts here.

146
00:17:38.190 --> 00:17:41.239
Vikesh K: By the way you can, you can try the app as well

147
00:17:41.550 --> 00:17:47.910
Vikesh K: at your end. I've I've sent it once. I will again send it so you can play with the app at your end.

148
00:17:49.230 --> 00:17:50.000
Vikesh K: Okay,

149
00:17:51.590 --> 00:18:00.519
Vikesh K: So let's say. But I think I should choose a different data sets, because some of these songs are very old. So I'm not sure many of you would have heard of these songs.

150
00:18:00.860 --> 00:18:03.410
Vikesh K: But yeah.

151
00:18:03.410 --> 00:18:09.489
shashi: Probably as exercise we can build our own and put it there in the streamline file and try our own recommendation.

152
00:18:09.490 --> 00:18:28.780
Vikesh K: Yeah, see every everything stream. It is awesome. It's not very difficult to learn. Streamlin. The good part is they allow you to host it for free. You just need to put some of this stuff in on Github, and then they allow you and they you can have this, you know, a dedicated URL, and then you can host everything for free.

153
00:18:28.880 --> 00:18:31.010
Vikesh K: It's very smooth that way. Actually.

154
00:18:31.890 --> 00:18:32.480
shashi: So

155
00:18:32.480 --> 00:18:50.621
shashi: some of the models. What I'm building for module 17 activity is taking 45 50 min and sk learn doesn't allow Gpu to be used, so I'm saving it as pickle file, so that I can at least run the test and other things later, and I don't have to wait 45 min to evaluate it

156
00:18:51.210 --> 00:18:53.199
shashi: or any other purpose.

157
00:18:53.340 --> 00:18:54.780
Vikesh K: Oh, lovely! Oh, that's great.

158
00:18:55.240 --> 00:19:11.470
Vikesh K: But yeah, let's say, you know, you're working on your company data set. Some people you know, often choose a company data set for their capstone. So let's say, you want to solve the problem and then internally deploy that thing. This could be one basic version as a prototype, which you can do. Okay? So

159
00:19:12.010 --> 00:19:23.989
Vikesh K: streamlit is cool so in case you're you manage to finish your capstone on time. And you're still curious. I would say, maybe try convert that into an app that would be really cool.

160
00:19:25.030 --> 00:19:25.890
Vikesh K: All right.

161
00:19:27.267 --> 00:19:36.179
Ravi Duvvuri: Question like for streamline? Do we need to know some other language or something, or is it it's? Is it on its own, or like, what do we need to know?

162
00:19:36.180 --> 00:19:58.998
Vikesh K: Yeah, streamlet is more. It's a python library, so it has its own. The documentation is very good off streamlit. So that's 1 good thing. And also, let's say in this. You know right now, if you get stuck somewhere you can actually use chat gpt, but I will. I will show you how easy it is to make something. So, for example, as I put St. Slider,

163
00:19:59.790 --> 00:20:03.400
Vikesh K: which I'm using here. So you go to the docs

164
00:20:04.249 --> 00:20:07.569
Vikesh K: streamlet has one of the best documentation out there.

165
00:20:07.700 --> 00:20:08.460
Vikesh K: And

166
00:20:09.790 --> 00:20:20.690
Vikesh K: so, for example, he's showing an example import streamlet, as St. You know, you put this age Slider and St. Dot, right? Okay, 3 lines of code.

167
00:20:21.330 --> 00:20:23.490
Vikesh K: And this is how it will look.

168
00:20:25.010 --> 00:20:26.930
Vikesh K: Okay. So it's a very cool app.

169
00:20:27.230 --> 00:20:39.840
Vikesh K: I would say, maybe you know it might. And you you would find a lot of material on Youtube as well, maybe 3 to 4 h, and you will be comfortable enough to make us a basic version basic app.

170
00:20:40.240 --> 00:20:41.080
Vikesh K: So

171
00:20:41.430 --> 00:21:05.520
Vikesh K: you know, I know many people, you know. Once you complete the course you will put it on your Github Linkedin. So along with when you announce that you know you've done the course. If you can also put your streamline code that will be really cool. All right, so try that. And then so so, as as you can see, there are a couple of code blocks here, 3 to 4 lines. Not much, and they can result in these sliders which you have.

172
00:21:06.340 --> 00:21:08.909
Vikesh K: So Streamliner is very, very good for making.

173
00:21:09.070 --> 00:21:22.630
Ravi Duvvuri: Where? Where did you like incorporate your recommendations into the code? Maybe I'm curious. On streamlit code. You have recommendations right? Those were popping up in the app. Can you go down on the page?

174
00:21:22.770 --> 00:21:26.610
Ravi Duvvuri: Yeah. These recommendations you must have plugged in the

175
00:21:26.770 --> 00:21:30.281
Ravi Duvvuri: Ml. Code somewhere, right into the streamlet app.

176
00:21:30.720 --> 00:21:34.220
Vikesh K: So how that happens is basically, the 1st part

177
00:21:34.330 --> 00:22:01.709
Vikesh K: is is simple filtering of that pandas data frame. The 1st part. That's what it is doing so. For example, let's say, you know, if I give you a pandas data frame. And I tell you, hey, I need something which danceability greater than 0 point 5 acousticness, 0 point greater than 5. So what you would do is pandas dot query. So you put all these things dot query, and then you will tell me, hey? Only 45, 55 songs match your criteria, and this is a list of those 55 songs.

178
00:22:01.930 --> 00:22:05.509
Vikesh K: Then the next step is you pass those songs

179
00:22:06.056 --> 00:22:19.950
Vikesh K: you. You select one of those songs, and that that one song which is selected that's passed through the pickle file, that pickle file which I exported here. All right. This pickle file is embedded in this streamlet code.

180
00:22:21.120 --> 00:22:28.099
Vikesh K: What it does that pickle file will generate will give recommendations and those recommendations, then I'm showing it here.

181
00:22:28.250 --> 00:22:31.020
Vikesh K: So the 1st part is completely pandas.

182
00:22:31.747 --> 00:22:38.339
Vikesh K: This part only on this part you need the pickle file, and then the recommendations get generated.

183
00:22:38.700 --> 00:22:40.300
Vikesh K: So it's pretty straightforward.

184
00:22:41.010 --> 00:22:41.770
Ravi Duvvuri: That's.

185
00:22:42.850 --> 00:22:45.230
Vikesh K: I can. I would have

186
00:22:46.360 --> 00:22:52.969
Vikesh K: code on my Github. I can. I can share that link. So if anyone of you are interested, please feel free to copy that

187
00:22:53.150 --> 00:22:55.149
Vikesh K: and use it for your own purpose.

188
00:22:55.770 --> 00:22:57.839
shashi: So this is where I select all the

189
00:22:58.100 --> 00:23:01.750
shashi: parameters for the model, and pass it as the

190
00:23:01.990 --> 00:23:06.660
shashi: for asking for the prediction to the model correct and then evaluate the.

191
00:23:06.660 --> 00:23:11.034
Vikesh K: Correct. So basically so so also, when you when you

192
00:23:13.454 --> 00:23:23.839
Vikesh K: let me let me share my screen again. Yeah. So the. I believe this is the right one. Yes, so this is. This is the where I've put the code.

193
00:23:23.970 --> 00:23:53.249
Vikesh K: So I will send the link so you can check it. I haven't done a lot of read me here. A very basic read me. But you can get the info from here. So this is the pickle file. So what happens in the Github? You need to put in all the details all right, and then you need to connect it to your streamlit cloud account. So only thing the streamlit cloud account will ask you, Hey, where is your Github file, or your Github port for repository. You link it to the Github Repository.

194
00:23:53.340 --> 00:23:57.619
Vikesh K: It will work on on its own and create the app, and that

195
00:23:57.850 --> 00:23:59.909
Vikesh K: the code for the app is this one

196
00:24:01.820 --> 00:24:07.709
Vikesh K: as you can see. See, the 1st part is, I'm using the sliders. So this is all pandas.

197
00:24:08.020 --> 00:24:15.600
Vikesh K: Then after that I'm using the pickle file and doing the predictions all right.

198
00:24:17.590 --> 00:24:33.620
Vikesh K: Give it a shot. This is like, you know, what it will do. It's obviously it's not mandatory for the course, but it will give you a hang of how to take your model and put it, you know. Convert this into some kind of front end so that users can interact with it.

199
00:24:33.770 --> 00:24:51.329
Vikesh K: Alright. Because if I tell you I have a recommendation system, you'll say, Okay, cool. But if I tell you, hey, you can use it. You can, you know, select songs. Let's say I'm you know, I listen to a lot of Bollywood. So if you put Bollywood songs in this, and then, you know, you change it. You you can get some nice recommendations.

200
00:24:51.660 --> 00:24:55.910
Vikesh K: alright any questions or doubts here.

201
00:24:59.310 --> 00:24:59.960
shashi: Government.

202
00:25:00.270 --> 00:25:00.840
Vikesh K: Food.

203
00:25:01.620 --> 00:25:18.310
Vikesh K: I hope at least the the idea got you excited that, you know, and and at least made you aware that you can do this. So if you're curious, please give it a shot. It won't take more than a weekend it's very simple to understand. And you know for starters. You can just replicate this code

204
00:25:18.460 --> 00:25:24.649
Vikesh K: and see if you can make up and your own stream it right? You start from this, and then you can further develop on. That

205
00:25:26.640 --> 00:25:27.600
Vikesh K: sounds good.

206
00:25:28.650 --> 00:25:29.550
Namrata: Okay.

207
00:25:30.100 --> 00:25:32.819
Vikesh K: So then we go to the second part.

208
00:25:34.610 --> 00:25:47.599
Vikesh K: Alright, so we are done with this, then the other one is which we learned in this course. And that's using surprise package, right? And that's where things become little more interesting. Because now you have

209
00:25:47.890 --> 00:26:00.869
Vikesh K: more sophisticated data set. So, for example, I have this one data set. We can see this. Let's do. Df, dot head. So this is a movie data set, simple one. But what you have is.

210
00:26:01.610 --> 00:26:15.600
Vikesh K: people have rated the movies. Alright. So a user id, one has seen this movie 31. And he has given a rating. Alright. So what you are trying to do in this is, will you will make this matrix

211
00:26:15.720 --> 00:26:18.220
Vikesh K: in which there is one user.

212
00:26:18.990 --> 00:26:25.169
Vikesh K: And you have this matrix with all the movie Ids, all the users

213
00:26:25.450 --> 00:26:33.090
Vikesh K: and their ratings. All right, rating, one rating 2. Some of it is missing, some of it is there so?

214
00:26:33.480 --> 00:26:49.309
Vikesh K: And this matrix. Then, you know, one of the techniques we use is the Svd to decompose this matrix into 3 different components. And I didn't use that to make predictions of the parts which are not available. So, for example, you have seen movie one

215
00:26:49.510 --> 00:26:59.329
Vikesh K: and Movie 2, but you haven't seen this one. I will use the rest of the matrix to make prediction for this one. Right? This is one of the that way more.

216
00:27:00.790 --> 00:27:11.514
Vikesh K: maybe a complicated week from that perspective, because this is like heavily into linear algebra. This is pure maths. You have to like really deal with the maths. But then,

217
00:27:13.080 --> 00:27:16.550
Vikesh K: And and you know if you don't get it in the first.st

218
00:27:16.840 --> 00:27:25.350
Vikesh K: go. That's fine, because I believe you might have to go back and read a lot of different concepts before you get a hang of it. The book which is.

219
00:27:25.670 --> 00:27:30.149
Vikesh K: you know, I had shown you that book. My machines learn. Where is that book? Maybe that book can help.

220
00:27:30.700 --> 00:27:55.660
Vikesh K: I will show it to you again. I think she also has one copy, and you have shown me so this is a good book to maybe get a hang of this. But other than that, I would say, I'm not sure how many of you are focusing on recommendation system for your capstone, but you get a hang of it, but I would say in terms of devoting efforts, put more efforts in the next week, which I believe is ensemble right next week is ensemble

221
00:27:56.370 --> 00:27:57.850
Vikesh K: after recommendation.

222
00:27:58.400 --> 00:28:00.310
Ravi Duvvuri: Yeah, I think, so, yeah.

223
00:28:00.310 --> 00:28:28.689
Vikesh K: So so ensemble as a concept would be more useful, more practical, also very, very helpful for your capsule, because at least in my batch. Most of the learners are doing either a regression or classification. I still haven't seen any unsupervised learning and recommendation. I have not seen anyone doing it, so ensemble would be more heavy. So when you have to prioritize, I would say, prioritize more on the ensemble. But get a basic idea of this one. Right?

224
00:28:29.500 --> 00:28:36.110
Vikesh K: So let's focus on this data set. We have. We are recording, right? Yes.

225
00:28:37.650 --> 00:28:43.509
Vikesh K: And to keep okay. So we have let me zoom in a bit.

226
00:28:44.300 --> 00:28:49.099
Vikesh K: we have 671 users in this one. And we have 9,000

227
00:28:49.250 --> 00:29:01.530
Vikesh K: movies. Okay, so this is how the data set looks like. Then obviously, the 1st thing you you would like to understand the basics of the data set, visualize make some visualizations, understand how things are looking like. So

228
00:29:02.190 --> 00:29:06.869
Vikesh K: this is the amount of reviews made by each. Each users. All right.

229
00:29:07.321 --> 00:29:23.889
Vikesh K: These are the reviews. These are the users. There are a bunch of users who have done a good amount of reviews. I've arranged this in ascending order, but to see, and also the second part is this is the distribution of the ratings. So most of the ratings were

230
00:29:24.070 --> 00:29:37.330
Vikesh K: users had given it 4.0, then 3.0, then 5.0. There were some very bad movies with very bad ratings. So the same chart is now represented in this format, in which I have arranged this in a

231
00:29:37.780 --> 00:29:52.429
Vikesh K: ascending order, all right, so that either you show it like this. Either you show like this information just to understand what's happening. But as you can see, most of the either the movies are too good, or maybe the users were very generous, because most of the movies have got a rating of 4.0.

232
00:29:52.760 --> 00:29:55.360
Vikesh K: That's the highest one. That's the mode.

233
00:29:56.310 --> 00:30:03.859
Vikesh K: Then, average number of reviews per users is 1, 49 right?

234
00:30:05.010 --> 00:30:08.290
Vikesh K: And let's see one more thing. Okay?

235
00:30:08.680 --> 00:30:13.710
Vikesh K: And this is more of the basic information.

236
00:30:14.480 --> 00:30:17.217
Vikesh K: Yeah, same thing. I'm trying to put visually

237
00:30:18.550 --> 00:30:22.770
Vikesh K: and how many movies and average number of reviews per user.

238
00:30:22.990 --> 00:30:29.449
Vikesh K: Okay, what? This was what I did average number of reviews per users, and average number of reviews.

239
00:30:33.530 --> 00:30:39.160
Vikesh K: I think this is something else which I've calculated here reviews number of view reviews

240
00:30:45.050 --> 00:30:46.969
Vikesh K: ignore this one, I would say.

241
00:30:47.810 --> 00:30:53.640
Vikesh K: focus on this one. So on an average one user has made 11 reviews. Alright

242
00:30:54.610 --> 00:31:03.260
Vikesh K: cool. So this is the basic premise. The data set is very simple. The main thing that we will use this is a different package is the surprise package that we use here.

243
00:31:03.410 --> 00:31:08.409
Vikesh K: And within that surprise has got 2 different algos. You have a support vector, decomposition.

244
00:31:11.107 --> 00:31:23.489
Vikesh K: the surprise package has got some again, it's it's it's more given in a theoretical you know, it's written in a very mathematical manner, but they give some info about it. How it works.

245
00:31:23.490 --> 00:31:42.729
Vikesh K: But and we will use that information that algorithm to do this. But the main thing is you need to 1st convert the data into the right format. So I will what it expects the data in the form of user Id, item, Id and write name, these are the 3 things it focuses on. So you focus on these 3 items from the data set.

246
00:31:43.200 --> 00:31:48.700
Vikesh K: and I will show you which is your user, Id, the movie Id, and the rating it gave alright.

247
00:31:49.100 --> 00:31:58.410
Vikesh K: So you convert this data set into the particular format and is, if you see, when you convert this into the format because it has to do the metric

248
00:31:59.020 --> 00:32:01.120
Vikesh K: factorization everything, I believe.

249
00:32:01.621 --> 00:32:09.400
Vikesh K: The he, you know the author of this package converted this into a specific format in which he can do the lean algebra pretty easily.

250
00:32:09.550 --> 00:32:18.349
Vikesh K: So this is the if you try to print it. This is in a very weird format, all right. So to make sense of it. Just to visualize it is a bit hard.

251
00:32:18.470 --> 00:32:23.389
Vikesh K: but at least what it does in the back end. It converts this into this particular format.

252
00:32:23.510 --> 00:32:42.699
Vikesh K: and then rest of the techniques. At least, what he has done is try to copy the cycle format in which you initialize the model, and then you fit it on the train set. All right. So you, these codes is where we have already imported the data set, reader. So this is the data set converter.

253
00:32:45.820 --> 00:32:50.330
Vikesh K: And then you have the algos. I'm using 2 basic algos here, and then you have the evaluation.

254
00:32:51.110 --> 00:32:54.310
Vikesh K: So you fit it on the train set.

255
00:32:54.986 --> 00:32:59.130
Vikesh K: You! And then, simple thing is, you make the predictions on the test set.

256
00:32:59.450 --> 00:33:09.120
Vikesh K: And remember, you know, you already have the test set data right? So you can check the root. Mean square error of the of your predictions.

257
00:33:09.220 --> 00:33:15.889
Vikesh K: Okay, you know this, this can be little confusing, because I think.

258
00:33:16.710 --> 00:33:19.709
Vikesh K: Let me see if they also call it accuracy.

259
00:33:21.210 --> 00:33:22.300
Vikesh K: One second.

260
00:33:26.830 --> 00:33:28.810
Vikesh K: I think I should just call it

261
00:33:29.200 --> 00:33:36.600
Vikesh K: not. The accuracy is not the right word to use here, because accuracy is for the classification. So I will say, the Rmsc. Yes.

262
00:33:37.630 --> 00:33:45.110
Vikesh K: cool. So the Rm. Rmsc. For this, for this technique was 0 point 9. So essentially what it does in the back end is.

263
00:33:45.520 --> 00:33:50.590
Vikesh K: it has got a user right and a movie.

264
00:33:51.620 --> 00:34:09.249
Vikesh K: And he let's say the user gave a rating of 4. And the algorithm Spd gave a rating of 3.9. All right. So and this is for all the movies. It sees. What is the actual and what is what was the predicted or predicted? Rating? All right.

265
00:34:10.050 --> 00:34:16.820
Vikesh K: the distance, and obviously the difference is calculated. So this is numerical. Hence what you calculate is root, mean squared error.

266
00:34:17.199 --> 00:34:22.550
Vikesh K: All right. So that's what that's what is happening in this stage. So you calculate this for Spd.

267
00:34:22.670 --> 00:34:27.220
Vikesh K: you can also do this for your Knn.

268
00:34:27.510 --> 00:34:29.869
Vikesh K: you know, you can call the basic in. And

269
00:34:30.110 --> 00:34:46.720
Vikesh K: now what you're doing, you're not doing the fancy factorization. But you're using a simple method in which you're trying to take a data point and find the neighbors nearest to it. All right, I think, by default, it takes 40 neighbors in this module.

270
00:34:46.870 --> 00:34:57.549
Vikesh K: Let me see if they have it in the documentation. Yes, K. Is equal to 40, so they use the simple. They use the 40 neighbors and try to see which movie would be closer to this movie.

271
00:34:57.900 --> 00:35:02.249
Vikesh K: Okay, this combo. And then when you try this.

272
00:35:03.480 --> 00:35:10.790
Vikesh K: at least in this case, Knn works better than your Svd, okay, so

273
00:35:10.910 --> 00:35:14.819
Vikesh K: be careful about this way, because Svd is a sophisticated technique.

274
00:35:15.330 --> 00:35:34.790
Vikesh K: But maybe there were too many missing values, right? You know it. How well the Svd works also will depend on how densely populated the whole matrix is. If there are too many gaps mostly, then maybe it won't do a good job, and here, at least in this case, the Knn. Did a better job than your Svd.

275
00:35:35.010 --> 00:35:38.029
Vikesh K: Alright so, and then you can.

276
00:35:38.300 --> 00:35:42.610
Vikesh K: Then obviously, then, since this is better, you can use this to make predictions.

277
00:35:42.840 --> 00:35:44.610
Vikesh K: This is one way

278
00:35:44.820 --> 00:35:59.520
Vikesh K: how you can look at the predictions. I've converted this into a pandas data frame. But what it will do is 3 things. One is the actual rating by the user. This is 5 point, oh, so this user Id. For this movie Id

279
00:35:59.800 --> 00:36:05.350
Vikesh K: had an actual rating of 5.0, estimated was 3.8, all right.

280
00:36:05.630 --> 00:36:22.940
Vikesh K: and the actual K, which was used to do. This was 40 and was impossible, tells you whether it was, you know, sometimes it's not possible to make a prediction, because maybe you don't have enough data points. So if was impossible, is true, that means

281
00:36:23.532 --> 00:36:31.779
Vikesh K: the model is not able to make the predictions. But since this is false in this case, that means it was able to make the predictions. And hence you can see the predictions here.

282
00:36:32.040 --> 00:36:33.779
Vikesh K: Alright. So

283
00:36:34.670 --> 00:36:46.840
Vikesh K: so what you see here is, let's say, this movie. This person for this movie had a rating of 2.0 real. But the estimated was 4.1 3. So this is what the predictions show you.

284
00:36:50.210 --> 00:36:56.019
Vikesh K: This is the real matrix. But now what we can do, and just to highlight.

285
00:36:58.660 --> 00:37:02.841
Vikesh K: I'm using the, you know, you can use the predict method to

286
00:37:03.806 --> 00:37:30.079
Vikesh K: you know, make a prediction of a movie. So let's say, you're interested in user 5 and item, 100, all right. So think about it is. If you're a Netflix, you have a user, and you have given him a tag of user 5. And he's looking in different movies. And maybe you know, the genre like one of the romance movie. Let's say there's item 100. What would be the likelihood of his interest? So you can generate the ratings here.

287
00:37:30.250 --> 00:37:36.910
Vikesh K: so as per Svd, it's around 3.6 5, and for Knn. This was 3.4 7

288
00:37:37.390 --> 00:37:43.690
Vikesh K: overall, because we saw Kn. Did a better job. So you know, you can go ahead with kn predictions right?

289
00:37:43.910 --> 00:37:50.170
Vikesh K: But this is how you generate the predictions from the different models here. So now, what I'm going to do

290
00:37:50.370 --> 00:37:54.539
Vikesh K: is I'm going to populate a data set which is based on the predictions.

291
00:37:55.260 --> 00:38:05.695
Vikesh K: So as you see, each row is a user id, each column is a movie. Id, okay?

292
00:38:06.250 --> 00:38:31.800
Vikesh K: what you want to do at a company level is that you should have all of it filled up so that anytime a user is there. And he's selecting logged into your website, you can give him a recommendation for any of the movings movie. Because, let's say, you have a user 6, 6, 9. By the way, I'm just filling it up, I'm making the structure. So that's why everything is 0. But let's say, user 6, 6, 9 logs into your website.

293
00:38:31.910 --> 00:38:52.097
Vikesh K: And then you have all these 9,000 movies in your library. Right? You can generate the recommend. You can generate the scores of for this user, and then just arrange this in a descending order and show it to him right or her whatever. So so this is one way, how you will use this information from

294
00:38:52.780 --> 00:38:56.870
Vikesh K: from this thing, from a front end perspective.

295
00:38:58.020 --> 00:39:14.279
Vikesh K: Okay? So what I'm doing at this stage is just running a painfully slow for loop in which for each movie, Id, for each user id, I'm selecting each movie Id, and I'm using the canon predictions

296
00:39:15.119 --> 00:39:36.890
Vikesh K: to generate a rating and then filling it up. Okay, the data frame. So it's again, this is 2 for loops. It's a huge data set. So this will take a good amount of time to run. But once this runs you will have a fully populated data set in which each row represents a user, and each column represents a rating. All right.

297
00:39:37.380 --> 00:39:39.990
Vikesh K: Now, let's say, if you're interested in the

298
00:39:43.050 --> 00:40:11.450
Vikesh K: in a recommendation system kind of thing. Maybe you download this kind of data set from goodreads. Or let's say, Netflix, some of these data sets are available on Kaggle. You can download it, make these prediction list, and then, you know, maybe convert this into a front end which will look like that spotify recommendation thing. Alright. So you can use that information so that for you select any user, and you will have the top 10 movies which he should see.

299
00:40:11.650 --> 00:40:19.040
Vikesh K: Okay, so that's something which you can do based on this pooled.

300
00:40:22.410 --> 00:40:27.990
Vikesh K: Okay? So I think I went a little fast.

301
00:40:28.420 --> 00:40:37.249
Vikesh K: But yeah, these are the. And again. Recommendation is very niche thing. Usually, if your company is in this business of

302
00:40:37.696 --> 00:40:54.863
Vikesh K: making recommendations it's customer centric, then it's a very useful technique skill to know. But I know maybe not. Every one of you would require this, and from a capstone perspective, especially if you're not doing this, I would say, now focus on the next week, once you do the assignments, or you know,

303
00:40:55.350 --> 00:40:58.490
Vikesh K: the required quizzes of this week. But

304
00:40:58.700 --> 00:41:05.699
Vikesh K: from my perspective and ensembles, which we will learn in the next week, would be very, very important to get a better hang of

305
00:41:07.630 --> 00:41:08.439
Vikesh K: all right.

306
00:41:09.210 --> 00:41:17.050
shashi: Yeah, even in agriculture, we can use this kind of this one like, if I have variables like nitrogen, potassium, and

307
00:41:17.710 --> 00:41:32.225
shashi: other pesticides or insecticides and other items which goes into crop, we can give them saying, Select this one, and these are the recommended products which are available. And you can use this kind of

308
00:41:33.320 --> 00:41:39.829
shashi: Oh, items on farming practices and things like that. It sounds very interesting.

309
00:41:40.470 --> 00:41:48.479
Vikesh K: Just to understand that idea. So for example, let's say, I go to a website, I select nitrogen. You're telling me what other fertilizers I should choose.

310
00:41:49.410 --> 00:42:09.650
shashi: Yeah, I mean, probably, I mean, which are if Field needs. If my soil test comes back saying that there is a poor npk, nitrogen, potassium, and phosphorus content is low, then we will know which are the products that are available which will augment the soil with this kind of

311
00:42:10.462 --> 00:42:13.657
shashi: nutrients, and then people can either

312
00:42:15.310 --> 00:42:22.820
shashi: vendor who's supplying can be listed there, and they can go directly to their site. Order it, or they will know at least. Okay, what is the optimal

313
00:42:24.790 --> 00:42:32.769
shashi: concentration that has to be present in the soil and based on business? Need. I mean whether we use it for selling the

314
00:42:33.050 --> 00:42:44.800
shashi: fertilizers, or any other components, or even recommending what kind of when to sow or when to harvest, and things like that, we can use data and make some kind of recommendation.

315
00:42:45.740 --> 00:42:48.780
Vikesh K: Oh, okay, okay, cool. That's good.

316
00:42:49.750 --> 00:42:50.930
Vikesh K: That's a good idea.

317
00:42:51.460 --> 00:42:52.070
shashi: Yeah.

318
00:42:54.020 --> 00:42:54.620
Vikesh K: Others.

319
00:42:54.620 --> 00:42:56.019
shashi: Lot of times we'll

320
00:42:56.740 --> 00:43:01.991
shashi: I mean in especially in India, North India, and all the government is doing

321
00:43:02.450 --> 00:43:12.639
shashi: they will tell, based on the weather input, they'll say, Okay, don't sow your seeds till another 8, 9 days, because the temperature is going to change.

322
00:43:12.770 --> 00:43:20.949
shashi: After that you saw the this one and 21 days after that, or 15 days after that, you put this this kind of fertilizers and chemicals.

323
00:43:21.100 --> 00:43:24.510
shashi: and these people. Government keeps sending

324
00:43:24.920 --> 00:43:28.019
shashi: kind of information to the farming community.

325
00:43:28.310 --> 00:43:36.420
shashi: So these kind of recommend recommendation systems and based on the other Npk has, I mean.

326
00:43:37.220 --> 00:43:40.069
shashi: environmental factors and all. We can use it.

327
00:43:41.190 --> 00:43:42.350
Vikesh K: Okay, okay.

328
00:43:43.200 --> 00:43:51.620
Vikesh K: you're I. I think you're the your special. You work around this. So you are the domain expertise. I I don't think I would be able to comment more on that. But yeah.

329
00:43:52.650 --> 00:43:54.600
Vikesh K: sounds like a good idea to me.

330
00:43:54.600 --> 00:43:55.860
shashi: Yeah, definitely.

331
00:43:56.830 --> 00:44:01.579
Vikesh K: Cool folks any other questions or doubt.

332
00:44:02.580 --> 00:44:05.299
Vikesh K: All of you have started working on your capstone. By the way.

333
00:44:07.360 --> 00:44:13.838
Ravi Duvvuri: Yeah, I have a good question. Yeah, no, that's what you know. What's the I I think.

334
00:44:14.400 --> 00:44:19.860
Ravi Duvvuri: there is a Eda deadline or something coming in a couple of weeks, or maybe

335
00:44:20.120 --> 00:44:22.819
Ravi Duvvuri: 12, th or something, or capstone.

336
00:44:24.050 --> 00:44:24.860
Vikesh K: Yeah.

337
00:44:25.300 --> 00:44:33.165
Ravi Duvvuri: Okay, okay? And I'm just looking at the timeline. And and you know, how can we complete 2 more exercises? And

338
00:44:33.800 --> 00:44:40.562
Ravi Duvvuri: the problem I selected was classification. So yeah, I'm rushing on these modules so that I can

339
00:44:41.560 --> 00:44:45.632
Ravi Duvvuri: focus on classification part of it. For my capstone.

340
00:44:46.360 --> 00:44:53.009
Vikesh K: I would. Why, I would. Let let me go through the passing criteria again quickly, because at this stage, usually.

341
00:44:53.250 --> 00:44:56.119
Vikesh K: if you think you're falling little behind.

342
00:44:56.860 --> 00:45:00.994
Vikesh K: I would, I think, I repeated this last time, but I would say,

343
00:45:02.050 --> 00:45:05.300
Vikesh K: we are in this one right? I would say, focus on the

344
00:45:05.720 --> 00:45:14.130
Vikesh K: last 3 parts more, because if you do these things, you're already 30 and 50, 70 or 70% there.

345
00:45:14.860 --> 00:45:39.619
Vikesh K: all right, these 3 capstone is mandatory in any case. So Capstone alone, will is 50% of your weight. So in case you are falling behind in other stuff, don't try to, you know, go back and finish each and every code you right now, because even if you do, it will take only 15%. It will give you only 15%. But the main thing where you will learn a lot. And also you need to. Mandatory. Complete is the capstone.

346
00:45:39.860 --> 00:45:46.969
Vikesh K: and that will take care of the 50%. So I will say, focus on the 3 big chunks, which is the practical applications and the capstone projects.

347
00:45:47.340 --> 00:45:48.000
Vikesh K: Alright.

348
00:45:48.000 --> 00:45:50.900
Kiran: Is a resubmissions allowed. If I want to.

349
00:45:51.140 --> 00:45:52.670
Vikesh K: In the practical or in the capstone.

350
00:45:52.670 --> 00:45:53.990
Kiran: In the capstone.

351
00:45:53.990 --> 00:45:55.300
Vikesh K: Yeah. Yes.

352
00:45:55.300 --> 00:45:55.730
Kiran: Okay.

353
00:45:55.730 --> 00:46:02.060
Vikesh K: Say, let's say someone made a mistake or something. We will just highlight it, and then we'll ask you to resubmit.

354
00:46:02.300 --> 00:46:07.674
Kiran: If I got like 40%, I want to say to 70%, I can rework and then submit again. Or

355
00:46:07.930 --> 00:46:23.190
Vikesh K: Yes, yes, yeah. Because let's say, you got 40%, maybe because let's say, some right technique wasn't used in the right manner. Or maybe some things were left right and you will be given that feedback. What is missing? Once you work on those things, you implement those things. And yeah, yeah, you can resubmi.

356
00:46:24.390 --> 00:46:25.510
Kiran: Got it. Thank you.

357
00:46:27.580 --> 00:46:31.630
Vikesh K: Any other questions on this. But yeah, I would say, as we are coming to the end.

358
00:46:31.860 --> 00:46:43.159
Vikesh K: See, you know initially, when we used to have this session. 40 50 people used to attend the office hours. Now it's around 10 of you, 11 of you. So this happens. Many people fall off on the way.

359
00:46:43.820 --> 00:46:55.559
Vikesh K: Many people, you know, get distracted, or they have 10 other things going on in their life. So be more strategic. At this stage, I would say, focus on the big chunks which will take you to the finish line.

360
00:46:55.800 --> 00:47:02.079
Vikesh K: because, you know, some of you would try to learn everything in depth right now, which is not possible. If you're falling behind.

361
00:47:02.290 --> 00:47:07.220
Vikesh K: so focus on the big chunks, get your certificate. Once you have your certificates, you have

362
00:47:07.470 --> 00:47:12.319
Vikesh K: access to the course for next one year. Right? So you can do a proper deep dive.

363
00:47:12.600 --> 00:47:32.630
Vikesh K: But at this stage it will become very crucial that all of you pass the course. I'm very. That's at least for very important for me that all of you get your certificates. So please be more strategic. Be more tactical. When you have one to one with your program, leader, please. Maybe if you have, this is a concern, please discuss it with them. They can give you some more insights.

364
00:47:33.030 --> 00:47:41.779
Vikesh K: But I would say, strongly, focus on the the getting the certificate that way. That means focusing on the big problems sets which will take you there.

365
00:47:42.330 --> 00:47:44.669
Vikesh K: Okay? Because, for example, codeyo

366
00:47:45.901 --> 00:47:58.880
Vikesh K: in a week, the amount of Cody activities that you do that's equivalent to a practical application, and that you have, I think, 2 or 3 practical applications. So that will. The vtage of practical application is more compared to a code activity.

367
00:47:59.290 --> 00:48:09.630
Vikesh K: Okay? And I believe many of you would have done many of the Cody activities, so at least you would be there, if not 15%, then at least maybe 7 to 8%. So you're already halfway there.

368
00:48:09.820 --> 00:48:14.350
Vikesh K: Alright. So you focus on the other chunks, get your 75% minimum.

369
00:48:15.010 --> 00:48:20.399
Vikesh K: And then you focus on the other parts. Matt has a question

370
00:48:21.580 --> 00:48:28.562
Vikesh K: we have no content for week. 20 can focus on just okay. Yeah. Week 20. There would be content. We can again.

371
00:48:28.880 --> 00:48:34.839
shashi: I think there is a break week on next 12 to 19, th or something like that. There is a break, I think.

372
00:48:34.840 --> 00:48:41.750
Vikesh K: Yeah, I think after ensemble there is a break. Yes, after ensemble. So you are in you. We did recommendation right?

373
00:48:42.352 --> 00:48:47.649
Vikesh K: Then ensemble is there, and then you have a break, and then you. We start on the neural networks and all.

374
00:48:48.830 --> 00:48:56.819
shashi: And so doing, Ead, and earlier evaluation, and all for image classifiers. What kind of

375
00:48:59.380 --> 00:49:21.430
shashi: task is required? Because I have images? I have kind of resized those 300 by 301, 28 by 1, 28, and grouping them so that which are the healthy ones which are the deceased one, and things like that, so will there be any other. Because we can't do much of plots and things like that. If it is an image classifier right? And then

376
00:49:21.960 --> 00:49:25.009
shashi: what kind of expectations are there for those.

377
00:49:28.356 --> 00:49:44.950
Vikesh K: Like base like in that sense I have. Maybe, Shasha, I didn't understand your question. So so the main thing what you're talking about is, you have to put it in a format which 1st of all, the algorithm will be able to consume it, and then you know it, and then generate the prediction in the same format. Right.

378
00:49:44.950 --> 00:49:49.834
shashi: Okay? No, no. What I was asking was the Ead activity. I think there is a

379
00:49:50.140 --> 00:49:50.870
Vikesh K: Oh! That!

380
00:49:50.870 --> 00:49:55.029
shashi: For this one the your people have to submit the Ead. And this.

381
00:49:55.030 --> 00:49:58.320
Vikesh K: Yeah, if you are doing. Yeah, I'm not sure about

382
00:49:59.670 --> 00:50:07.219
Vikesh K: yeah. What exactly you can do. Ed, if you just have a like the matrix data of images. What? What, Ed, you can show me.

383
00:50:07.760 --> 00:50:10.769
shashi: Okay, sample images. And what kind of data?

384
00:50:11.700 --> 00:50:15.039
shashi: Part of that one that will help. Yeah, okay, that I can.

385
00:50:15.380 --> 00:50:22.060
Vikesh K: Yes, like the basic stuff, you know what. So so, for example, let's say, if I look at your Ed, I understand what this data set is about.

386
00:50:22.370 --> 00:50:23.400
shashi: Oh, okay. Fine. Yeah.

387
00:50:23.400 --> 00:50:33.229
Vikesh K: Right? Any outliers, anything, anything weird? I'm not sure what would be an outlier there. But yeah, anything which helps me get familiar with your data set.

388
00:50:33.820 --> 00:50:34.960
shashi: Sure. Okay. Yeah.

389
00:50:34.960 --> 00:50:41.649
Ravi Duvvuri: Yeah. And Sasha, that was my question. Like, you know, I saw that deadline like your Eda, we have to submit. You know.

390
00:50:41.860 --> 00:50:55.920
Ravi Duvvuri: Yeah, I was wondering. I have image classification as well. So, and some of the things like I was told that week 2122 will will help me with more techniques on classification. So I, you know.

391
00:50:56.370 --> 00:50:59.250
Ravi Duvvuri: I need to do something for Eda. So yeah.

392
00:50:59.430 --> 00:51:04.304
shashi: Yeah, same, I think that break week will go for the complete. This only.

393
00:51:05.030 --> 00:51:05.910
Ravi Duvvuri: Yeah, exactly.

394
00:51:07.360 --> 00:51:17.580
Vikesh K: One thing also, you know, it's great that you, all of you, are choosing these, you know, challenging problems, I believe maybe when the professors decided they they thought

395
00:51:17.790 --> 00:51:31.129
Vikesh K: most of the folks, and that that's what we have also seen. Even in this batch. Most of the people will pick up a tabular problem, which is, you have rows and columns right like, let's say, loan classification or something, and within that there's a good scope of Ada.

396
00:51:31.310 --> 00:51:37.991
Vikesh K: So but if you have a very specialized problem in which maybe there's not a lot of scope of Ada, maybe

397
00:51:39.106 --> 00:51:44.160
Vikesh K: focus on the things which will help others to understand the data set. What the data set is about.

398
00:51:45.010 --> 00:51:50.279
shashi: In my case, I mean, if the image has like, if I'm detecting a disease from a list.

399
00:51:50.590 --> 00:52:15.010
shashi: primary area of the object should be the leaf, I mean, where the disease is seen. I can't show the bark or ground, or a hand, or something like that, holding the leaf, and things like. So that kind of I have to peruse all the images and make sure I don't have any extraneous material, because you shouldn't see black mark on my hand as a disease and say, it is diseased plant and things like that. So I have to clean up those kind of activities. I have to do.

400
00:52:15.240 --> 00:52:21.533
Vikesh K: Yeah. And also I would. I would recommend both. I I think both of you are in a different section than mine. So you know. Just talk to your

401
00:52:22.000 --> 00:52:23.859
Vikesh K: you know, pro program leader.

402
00:52:24.040 --> 00:52:27.820
shashi: Right money I have to. I have to talk.

403
00:52:27.820 --> 00:52:32.349
Vikesh K: Expectations. Yeah. Set expectations with them, so that.

404
00:52:32.350 --> 00:52:32.700
shashi: Yeah.

405
00:52:32.700 --> 00:52:40.280
Vikesh K: They're aware of what's like if you're working on a very niche kind of problem. So they are aware of it, and then be they will guide you what they expect

406
00:52:41.024 --> 00:52:51.850
Vikesh K: evaluate your project right? So so the so if you're in mind, maybe this is how I would say it. But let's say you know you talk to others and see what ideas they have on this.

407
00:52:52.690 --> 00:52:53.520
shashi: Yeah. Oh.

408
00:52:55.070 --> 00:52:55.690
Vikesh K: Cool.

409
00:52:57.610 --> 00:52:59.850
Vikesh K: Okay. Any other questions or doubts.

410
00:53:01.400 --> 00:53:26.200
Zhujun Wang: I have a just quick question about the Svd. And kn rooming square arrow. So it's almost like close 0 point 9 something point close to like. So so since rating is probably, I remember, is from one to 4. So so consider, that is, is, it is not not a very good recommendation

411
00:53:26.440 --> 00:53:32.920
Zhujun Wang: algorithm to use, or usually for, for this kind of like a rooming square arrow is a

412
00:53:33.980 --> 00:53:37.550
Zhujun Wang: within the reasonable range. That's my question.

413
00:53:38.476 --> 00:53:40.930
Vikesh K: You mean the the 2 ratings that.

414
00:53:40.930 --> 00:53:49.960
Zhujun Wang: Yeah, like for this 1 0 point 9 or 0 point 9 7. And because most, I think the see the like input data ratings from

415
00:53:50.360 --> 00:53:59.320
Zhujun Wang: probably from 0 to 4 or something. Right? So so if a average like arrow is 0 point 9. So which means when I

416
00:53:59.730 --> 00:54:07.459
Zhujun Wang: predict maybe the rating, whatever will be kind of off

417
00:54:07.750 --> 00:54:11.600
Zhujun Wang: little bit more like. Is it my understanding correct?

418
00:54:11.770 --> 00:54:16.325
Vikesh K: Okay, so so what? How? What essentially this means is like, you know, you have.

419
00:54:17.720 --> 00:54:30.700
Vikesh K: errors. Your root mean square error from the both. So let's say you have Knn predictions, and you have Svd predictions right? And you will get some root mean square error from this. So 0 0 point 9 is.

420
00:54:31.370 --> 00:54:36.560
Vikesh K: it's basically, yes.

421
00:54:37.240 --> 00:54:39.070
Zhujun Wang: Yeah, that's what I mean. Because after that.

422
00:54:39.070 --> 00:54:39.690
Vikesh K: Aye.

423
00:54:39.690 --> 00:54:41.610
Zhujun Wang: You used these, these.

424
00:54:41.610 --> 00:54:41.980
Vikesh K: Yes.

425
00:54:41.980 --> 00:54:53.079
Zhujun Wang: Model to predict, you know, unknown, I'm reading the movie, or whatever like try to recommend to people. But since, like I feel like this offset a little bit. Big.

426
00:54:54.470 --> 00:54:55.419
Vikesh K: Correct, correct, correct.

427
00:54:55.420 --> 00:54:56.589
Zhujun Wang: Yeah, that's my point, yeah.

428
00:54:56.590 --> 00:54:57.870
Vikesh K: Correct. Yes.

429
00:54:58.020 --> 00:55:07.209
Vikesh K: you know what I did. Yes, thanks for highlighting that I now realized it while while again talking about it. So this one. Yes, this one sud is actually better.

430
00:55:07.210 --> 00:55:15.909
shashi: Yes, you know I had that doubt. I mean yesterday. The low is the lowest, and I was thinking about that one only correct. Yeah.

431
00:55:16.180 --> 00:55:38.239
Vikesh K: Oh, sorry my video got switched off. No, but oh, thanks. So you know, I think maybe I made that silly mistake. I had written accuracy. And then I started thinking in terms of accuracy, now that you again highlighted it. Apologies for that. But yes, this should not. Yes, then, in this case Knn should not be used. The root mean square error, which is basically the measure of the error. Svd actually does a better job.

432
00:55:38.883 --> 00:55:42.819
Vikesh K: Okay. Sorry sorry for that, folks. But this is

433
00:55:44.620 --> 00:55:47.040
Vikesh K: Mr. Bank. I'm not sure how to pronounce your name.

434
00:55:47.040 --> 00:55:48.400
Zhujun Wang: Yeah, you can call me Zoo, actually.

435
00:55:48.686 --> 00:55:52.589
Vikesh K: Okay, zoom, yeah, yeah, this is a good good thing. Thank you. Thank you for highlighting that.

436
00:55:53.030 --> 00:56:06.550
Vikesh K: Okay, so yes, I I will also change the code to focus on the svd, yeah, I don't know. Very silly of me. I was thinking of it in terms of at that time accuracy. I think I was changing it. And I was like, Okay, oh, maybe this is okay.

437
00:56:06.980 --> 00:56:24.310
Vikesh K: That's a silly mistake. But yes, then Svd is a better one and 0 point 9, which is like, you know, on an average, you're one by 1 point off. So let's say your rating is from 0 to 5. So for every rating you, you're off by 1 point, I believe.

438
00:56:24.310 --> 00:56:32.289
Zhujun Wang: 1 point. So sounds like it's still the little bit big gap, right? Like points like, okay, gotcha. Okay.

439
00:56:32.750 --> 00:56:34.889
Vikesh K: Cool. But but thank you for highlighting that.

440
00:56:35.660 --> 00:56:38.839
Vikesh K: Okay, any other points.

441
00:56:41.120 --> 00:56:41.680
Zhujun Wang: Oh.

442
00:56:41.680 --> 00:56:57.850
Zhujun Wang: last question. So since, like last remember, I remember last section, say, say, they say, usually for recommendation system. Probably we can hybrid multiple algorithm together. So, for example, right now

443
00:56:58.230 --> 00:57:03.530
Zhujun Wang: compose Svd and and Kn. And S Svd

444
00:57:03.730 --> 00:57:18.940
Zhujun Wang: probably is better. And after that, if we want to make a further improvement. May I need to like, combine, consider more factor or like, combine the maybe different algorithm together, like.

445
00:57:19.950 --> 00:57:20.939
Vikesh K: What's the general.

446
00:57:20.940 --> 00:57:21.500
Zhujun Wang: Coach.

447
00:57:21.620 --> 00:57:43.780
Vikesh K: Yeah. So in practice, I believe you know, the data sets that we have are slightly more comprehensive. For example. You know, one thing. You can also do it. You know, you can also combine multiple methods is, let's say, we have the movie data. But we don't have a lot of information about that movie. So, for example, the spotify example that we did, we had a lot of numerical information about a song.

448
00:57:43.940 --> 00:57:50.739
Zhujun Wang: We can actually have more of those information about a movie and use that incorporate that as well.

449
00:57:51.190 --> 00:58:03.480
Vikesh K: Okay. So so though, because right now, this is just like, okay, this is one user. This is how he has rated a movie. Okay, you don't have any other information. But if you add more information about

450
00:58:03.720 --> 00:58:04.840
Vikesh K: a movie

451
00:58:05.609 --> 00:58:19.829
Vikesh K: or maybe even for users that, can that can give you more insights that can add more elements to this. So maybe you can also have a combined effect. You know, you can also have a weighted way of doing these recommendations. You know.

452
00:58:20.310 --> 00:58:22.049
Zhujun Wang: Does that? Okay? Do?

453
00:58:22.050 --> 00:58:24.879
Zhujun Wang: Oh, make make sense. Okay.

454
00:58:25.480 --> 00:58:29.189
Vikesh K: So that that will involve more more sophisticated data set essentially.

455
00:58:29.970 --> 00:58:30.790
Zhujun Wang: Gotcha.

456
00:58:32.150 --> 00:58:39.700
Vikesh K: Cool, cool, I think any other questions, or we can call it a day.

457
00:58:40.550 --> 00:58:42.179
Vikesh K: Anything on the capstone.

458
00:58:43.319 --> 00:58:52.180
Ravi Duvvuri: No, no, just a question on the classification. Do you have any recommended book, or anything particularly to go through? As a reference.

459
00:58:52.550 --> 00:58:55.650
Ravi Duvvuri: any recommendations issue.

460
00:58:55.650 --> 00:58:59.360
Vikesh K: I I had this I had this preparedness.

461
00:59:00.520 --> 00:59:04.570
Vikesh K: this resource page. I believe I'm not sure how many of you are aware of it.

462
00:59:04.570 --> 00:59:08.559
Ravi Duvvuri: Tracking to that. I maybe I didn't check for for this particular one.

463
00:59:09.040 --> 00:59:11.159
Vikesh K: Okay. So within that.

464
00:59:13.440 --> 00:59:23.460
Vikesh K: yes, I will do that. So if you go at the bottom. So I've I've tried to make it weekly. I've given wherever I found some interesting links. I've put those links here.

465
00:59:24.880 --> 00:59:28.230
Vikesh K: At the bottom you have couple of book recommendations.

466
00:59:29.210 --> 00:59:33.879
Vikesh K: and all of them are free. This is a good book for theoretical understanding.

467
00:59:34.652 --> 00:59:41.919
Vikesh K: But let's say you want more hands on python code. So this is a good book to go through, and what it does.

468
00:59:44.810 --> 00:59:59.710
Ravi Duvvuri: No for class. I got this ones for classification in particular. So like one of the book you guys recommended was nlp in the course. So that's pretty good. Similarly, anything specific to classification.

469
00:59:59.710 --> 01:00:00.926
Vikesh K: So so within that

470
01:00:01.400 --> 01:00:19.999
Vikesh K: like, for example, how you focus on classification is you have, let's say, you know, 4 basic 5 basic algorithms. Right? You have logistic support support vector classifier, you have decision tree, random forest. So then, what he has done, he has covered all these algorithms, at least the main algorithms, if not all but the main ones.

471
01:00:20.400 --> 01:00:21.390
Vikesh K: So

472
01:00:21.900 --> 01:00:32.120
Vikesh K: you can use that like, learn. If you have any particular in mind, you let me know because classification again, classification has got multiple techniques. So which technique you want to focus on.

473
01:00:32.130 --> 01:00:39.410
Ravi Duvvuri: Yeah, I think more like, the neural networks like Cnn, I think I got these 4. Which I think we can use.

474
01:00:39.410 --> 01:00:40.590
Ravi Duvvuri: Oh, okay, fine.

475
01:00:40.590 --> 01:00:41.710
Ravi Duvvuri: To clarify.

476
01:00:41.710 --> 01:00:45.310
Vikesh K: For let's say you want to do a machine learning.

477
01:00:45.970 --> 01:00:54.109
Vikesh K: There is a machine learning book in itself, and this book of late has got received a lot of good recommendation or not. This one once again.

478
01:00:55.067 --> 01:00:57.099
Vikesh K: Understanding, deep learning.

479
01:00:57.400 --> 01:01:06.660
Vikesh K: Okay, so this is one book which you can focus if you want to. Where is that content-content?

480
01:01:07.540 --> 01:01:13.760
Vikesh K: You can download the whole thing. But I wanted to show you the content, if possible. No, okay, let me click on the

481
01:01:13.880 --> 01:01:17.229
Vikesh K: Pdf, right? It will download it.

482
01:01:17.550 --> 01:01:18.460
Vikesh K: And

483
01:01:22.600 --> 01:01:26.200
Vikesh K: if you check this, yeah. So you have the

484
01:01:26.740 --> 01:01:29.210
Vikesh K: discussion on the neural networks in this one.

485
01:01:30.090 --> 01:01:32.199
Vikesh K: If if you're curious about that.

486
01:01:32.330 --> 01:01:39.029
Vikesh K: By the way, I when I open this python data science handbook, it has this one chapter on a face detection pipeline.

487
01:01:39.250 --> 01:01:43.670
Vikesh K: So maybe how he approaches. It might be helpful for your project as well.

488
01:01:43.900 --> 01:01:47.840
Vikesh K: Okay. And let's say how he does the Ed and all so.

489
01:01:48.480 --> 01:01:52.970
Vikesh K: or how he develops the whole model. Maybe you can test this at your end as well.

490
01:01:53.640 --> 01:01:54.900
Ravi Duvvuri: Got it? Yeah, yeah.

491
01:01:54.900 --> 01:01:56.930
Vikesh K: Okay, so try this out.

492
01:01:59.000 --> 01:02:01.149
Vikesh K: And Matt also shared something.

493
01:02:01.570 --> 01:02:03.270
Vikesh K: Maybe check that out as well.

494
01:02:05.660 --> 01:02:19.730
Vikesh K: Cool. But yeah. Key key bookmark. This because I will keep updating this also going forward. So even after the course, maybe you might find some nice links or helpful links here and many times. I understand some of the

495
01:02:20.030 --> 01:02:27.700
Vikesh K: explanations can are found which are better on Youtube. So maybe you know, you can find some of these from here as well.

496
01:02:29.080 --> 01:02:29.830
Ravi Duvvuri: Thank you.

497
01:02:30.080 --> 01:02:32.430
Vikesh K: Alright cool.

498
01:02:32.990 --> 01:02:37.420
Vikesh K: Then thanks again. And zoo, thank thank you again for highlighting that. Yeah, my bad.

499
01:02:37.640 --> 01:02:43.589
Vikesh K: And we'll see you, by the way. So when we have the, you know, upcoming weeks.

500
01:02:43.730 --> 01:02:54.640
Vikesh K: there might be a slight okay from Feb. 19 till, I believe. Yes, till the end of the course. My office are timings will change. It might be a bit more earlier. I'm going to India for a month

501
01:02:54.860 --> 01:03:01.830
Vikesh K: so sadly the timings will change. I know it might be inconvenient for some of you apologies for that in advance.

502
01:03:02.426 --> 01:03:04.789
Vikesh K: I will send you the, and there might be few

503
01:03:05.120 --> 01:03:09.029
Vikesh K: things moving around here and there, because I will be traveling within India.

504
01:03:09.150 --> 01:03:13.569
Vikesh K: So apologies for that in advance, but like

505
01:03:13.970 --> 01:03:20.519
Vikesh K: I don't think the timings like will happen at this time. This is like 2, 33 am. In India. I don't think I will be able to do that.

506
01:03:21.390 --> 01:03:30.689
Vikesh K: Maybe initial one or 2, 1 or 2 weeks, but not not after that. That will distort my sleep cycle. So so forgive for that. Forgive me for that, and

507
01:03:31.320 --> 01:03:37.550
Vikesh K: apologies for that in advance, but hope to see. Meet you on Feb. 19th now.

508
01:03:37.690 --> 01:03:44.930
Vikesh K: or maybe February. I might have to change this because I'm traveling on 18.th I will keep an update. Keep you guys updated on this.

509
01:03:45.420 --> 01:03:46.190
Vikesh K: All right.

510
01:03:47.030 --> 01:03:48.419
Ravi Duvvuri: Okay, have a good journey.

511
01:03:48.670 --> 01:03:49.110
Vikesh K: Cool.

512
01:03:49.110 --> 01:03:49.720
Zhujun Wang: Thank you.

513
01:03:49.720 --> 01:03:56.810
Vikesh K: Thank you. Thanks a lot and see you in Feb. After 2 after 1. 0, no, there's a break week after 2 weeks.

514
01:03:57.250 --> 01:03:59.710
Vikesh K: Cool cheers bye, everyone.

515
01:04:00.560 --> 01:04:01.240
Zhujun Wang: Thank you.

