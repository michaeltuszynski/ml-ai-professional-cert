# Overview

In this third practical application assignment, your goal is to compare the performance of the classifiers (k-nearest neighbors, logistic regression, decision trees, and support vector machines) you encountered in this section of the program. You will use a dataset related to the marketing of bank products over the telephone.

## Data

The dataset you will use comes from the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/). The data is from a Portuguese banking institution and is a collection of the results of multiple marketing campaigns. Please see the following link to access the assignment:

[Required Assignment 17.1](https://example.com)

## Deliverables

After understanding, preparing, and modeling your data, build a Jupyter Notebook that includes:
- A clear statement demonstrating your understanding of the business problem
- A correct and concise interpretation of descriptive and inferential statistics
- Your findings (including actionable insights)
- Next steps and recommendations

### Submission Instructions:
1. Submit the website URL to your public-facing GitHub repository here.
2. Your Program Leader will grade your submission according to the rubric below.
3. The average completion time for this assignment is 15 hours.

## Grading

Please note that you will be awarded points based on this activity. You may refer to the rubric below to know more about the grading criteria.

### Rubric: Required Assignment 17.1: Comparing Classifiers

#### Project Organization (5 points)
- A READMe file with a summary of findings and a link to the Jupyter Notebook
- Jupyter Notebook has headings and text appropriately formatted
- No unnecessary files
- Directories and files have appropriate names and locations

**Excellent (5 pts)**: Your submission includes all of the listed components.
**Criterion not met (0 pts)**: Your submission includes a few or none of the listed components.

#### Syntax and Code Quality (5 points)
- Libraries are imported and aliased correctly
- Code does not contain errors
- No long strings of code output
- Demonstrates competency with pandas
- Demonstrates competency with seaborn
- Comments are used appropriately to explain code
- Variables are sensible

**Excellent (5 pts)**: Your submission includes all of the listed components.
**Criterion not met (0 pts)**: Your submission includes a few or none of the listed components.

#### Visualizations (5 points)
- Appropriate plots for categorical and continuous variables are utilized
- Plots contain readable labels
- Plots contain descriptive titles
- Axes are legible
- Subplots are used when appropriate
- Plots are scaled appropriately for readability

**Excellent (5 pts)**: Your submission includes all of the listed components.
**Criterion not met (0 pts)**: Your submission includes a few or none of the listed components.

#### Modeling (5 points)
- Use of multiple regression models
- Cross-validation of models
- Grid search hyperparameters
- Appropriate interpretation of coefficients in models
- Appropriate interpretation of an evaluation metric
- Clear identification of an evaluation metric
- Clear rationale for use of the given evaluation metric

**Excellent (5 pts)**: Your submission includes all of the listed components.
**Criterion not met (0 pts)**: Your submission includes a few or none of the listed components.

#### Findings (5 points)
- Clearly stated business understanding of the problem
- Clean and organized notebook with data cleaning
- Correct and concise interpretation of descriptive and inferential statistics
- Clearly stated findings in their own section with actionable items highlighted in appropriate language for a nontechnical audience
- Next steps and recommendations