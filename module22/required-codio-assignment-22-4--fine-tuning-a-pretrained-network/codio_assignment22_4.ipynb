{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "13970d47824a047689fd73b5292c2d15",
     "grade": false,
     "grade_id": "cell-1af27d3e65f74335",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Required Codio Assignment 22.4: Fine-Tuning a Pretrained Network\n",
    "\n",
    "**Expected Time = 60 minutes**\n",
    "\n",
    "**Total Points = 30**\n",
    "\n",
    "In addition to the use of a pre-trained network to extract features from a different dataset, the weights can be adjusted or **fine-tuned** as a last step to squeeze additional performance from the network.  To do so, you will again use the `EfficientNetV2B0` network on the `cifar10` data from `keras`.  This time you are encouraged to use the functional API syntax to construct your network.  \n",
    "\n",
    "For a second example, consult the `keras` documentation example [here](https://keras.io/guides/transfer_learning/). \n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "\n",
    "Run the code cell below to import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B0\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import Model, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "sub_indices = pd.DataFrame(y_train, columns= [\"labels\"]).groupby('labels', group_keys=False).apply(lambda x: x.sample(frac=0.3, random_state=123)).index\n",
    "X_train = X_train[sub_indices]\n",
    "y_train = y_train[sub_indices]\n",
    "\n",
    "Y_train = to_categorical(y_train)\n",
    "Y_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e34520b368d3d01a34666b8e161ee857",
     "grade": false,
     "grade_id": "cell-c8d37aca8ee95d87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Training the Network to Convergence\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "In the code cell below, use the function `EfficientNetV2B0` with the appropriate input shape and the argument `include_top` equal to `False` to create the model you will be using for this activity. Assign your result to `base_model`.\n",
    "\n",
    "Use the function `Input()` with argument `shape` equal to `(32, 32, 3)` and assign your result to the variable `inputs`.\n",
    "\n",
    "Use `base_model` with argument equal to `inputs` and assign your result to the variable `x`.\n",
    "\n",
    "Use the function `Flatten` to flatten `x`. The pseudocode to complete this step is given below:\n",
    "\n",
    "```Python\n",
    "x = Flatten()(...)\n",
    "```\n",
    "\n",
    "Pass `x` through a `Dense` layer with 100 hidden nodes and `activation` equal to `relu` and assign the result to the variable `output`. The pseudocode to complete this step is given below:\n",
    "\n",
    "```Python\n",
    "output = Dense(..., activation = ...)(...)\n",
    "```\n",
    "\n",
    "Use the code `base_model.trainable = False` to ensure that your weights are not trainable.\n",
    "\n",
    "Use the function `Model()` with argument `inputs` and `output` to define your model. Assign the result to the variable `model`.\n",
    "\n",
    "Compile `model` using `categorical_crossentropy` as your `loss` and `accuracy` as your `metric`.\n",
    "\n",
    "Use the `fit()` function on `model` to fit the  training data `X_train` and `Y_train`. Set the argument `validation_data` equal to `(X_test, Y_test)` and the argument `epochs` equal to 1.  Assign the result to the variable `bottom_model` below. \n",
    "\n",
    "NOTE: This question is computationally expensive, so please be patient with the processing. It may take a few minutes based on your computing power. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06e74ff5270af05f7fd75aef58b5b91d",
     "grade": false,
     "grade_id": "cell-e92e20d0c85d3026",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 18s 34ms/step - loss: 1.6989 - accuracy: 0.4402 - val_loss: 1.4366 - val_accuracy: 0.5161\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " efficientnetv2-b0 (Functio  (None, 1, 1, 1280)        5919312   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                12810     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5932122 (22.63 MB)\n",
      "Trainable params: 12810 (50.04 KB)\n",
      "Non-trainable params: 5919312 (22.58 MB)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " efficientnetv2-b0 (Functio  (None, 1, 1, 1280)        5919312   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                12810     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5932122 (22.63 MB)\n",
      "Trainable params: 12810 (50.04 KB)\n",
      "Non-trainable params: 5919312 (22.58 MB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "base_model = ''\n",
    "inputs = ''\n",
    "x = ''\n",
    "x = ''\n",
    "x = ''\n",
    "output = ''\n",
    "model = ''\n",
    "#be sure to compile\n",
    "\n",
    "bottom_model = ''\n",
    "\n",
    "# YOUR CODE HERE\n",
    "base_model = EfficientNetV2B0(input_shape=(32, 32, 3), include_top=False, weights='imagenet')\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "x = base_model(inputs)\n",
    "x = Flatten()(x)\n",
    "output = Dense(10, activation='softmax')(x)\n",
    "base_model.trainable = False\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "bottom_model = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=1)\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(model.summary())\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b83eb00a52364595f510b8efcf820e0",
     "grade": true,
     "grade_id": "cell-c7a974852163092b",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " efficientnetv2-b0 (Functio  (None, 1, 1, 1280)        5919312   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                12810     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5932122 (22.63 MB)\n",
      "Trainable params: 12810 (50.04 KB)\n",
      "Non-trainable params: 5919312 (22.58 MB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ef81cb1cb42ba5c0c99bd6d4bc6eb42",
     "grade": false,
     "grade_id": "cell-72d9644d3c68011b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Setting to Trainable\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "In the code cell below, use the code `base_model.trainable = True` to ensure that your weights are now trainable.\n",
    "\n",
    "\n",
    "Set the final five layers to trainable in the `base_model` as demonstrated in the lectures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.trainable #are the base model weights set to trainable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "465df4f734e0174f0d0a543277c31b5a",
     "grade": false,
     "grade_id": "cell-17e4f0a4de6dc3b8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer is trainable: False\n",
      "Layer is trainable: False\n",
      "Layer is trainable: False\n",
      "Layer is trainable: False\n",
      "Layer is trainable: False\n",
      "Layer is trainable: True\n",
      "Layer is trainable: True\n",
      "Layer is trainable: True\n",
      "Layer is trainable: True\n",
      "Layer is trainable: True\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "base_model.trainable = True\n",
    "for layer in '':\n",
    "    #make trainable\n",
    "    pass\n",
    "\n",
    "# YOUR CODE HERE\n",
    "for layer in base_model.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "### ANSWER CHECK\n",
    "for i, layer in enumerate(base_model.layers[-10:]):\n",
    "    print(f'Layer is trainable: {layer.trainable}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "963ff0ce2fd1f10e325f223a5842c19f",
     "grade": true,
     "grade_id": "cell-279935493600bece",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "99b3ed750346d6f4397a636ed7a70dfa",
     "grade": false,
     "grade_id": "cell-0307a936396eedc2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Refitting the network\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "In the code cell below, use the function `compile` on `model` using `categorical_crossentropy` as your `loss` and `accuracy` as your `metric`.\n",
    "\n",
    "Next, use the `fit()` function on `model` to fit the  training data `X_train` and `Y_train`. Set the argument `validation_data` equal to `(X_test, Y_test)` and the argument `epochs` equal to 1.  Assign the result to the variable `fine_tuned_history` below. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "368204078562a399aa8f7a4c82b0df6b",
     "grade": false,
     "grade_id": "cell-75f43fbafe9c0840",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 18s 33ms/step - loss: 1.5721 - accuracy: 0.5106 - val_loss: 1.1811 - val_accuracy: 0.6129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5105999708175659"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "fine_tuned_history = ''\n",
    "\n",
    "# YOUR CODE HERE\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "fine_tuned_history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=1)\n",
    "\n",
    "\n",
    "### ANSWER CHECK\n",
    "fine_tuned_history.history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Summary: Fine-Tuning a Pretrained Network\n",
    "\n",
    "## Exercise Overview\n",
    "\n",
    "This notebook contains three key exercises that demonstrate transfer learning and fine-tuning techniques using the EfficientNetV2B0 architecture on the CIFAR-10 dataset.\n",
    "\n",
    "### Problem 1: Building a Feature Extraction Model\n",
    "- Creating a base model using EfficientNetV2B0 with pretrained weights\n",
    "- Setting up a functional API model with frozen base weights\n",
    "- Adding custom classification layers (Flatten and Dense)\n",
    "- Training the model while keeping the pretrained weights fixed\n",
    "\n",
    "### Problem 2: Configuring Fine-Tuning\n",
    "- Enabling trainable weights in the base model\n",
    "- Selectively freezing layers (making only the last 5 layers trainable)\n",
    "- Preserving low-level feature extraction capabilities while allowing high-level features to adapt\n",
    "\n",
    "### Problem 3: Fine-Tuning the Network\n",
    "- Recompiling the model after layer modifications\n",
    "- Training the partially unfrozen model on the dataset\n",
    "- Leveraging both pretrained features and dataset-specific adaptations\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Transfer Learning Strategy:** The notebook demonstrates how to leverage pretrained networks for new tasks, reducing training time and data requirements.\n",
    "\n",
    "2. **Feature Extraction vs Fine-Tuning:**\n",
    "   - Feature extraction: Using pretrained model with frozen weights (Problem 1)\n",
    "   - Fine-tuning: Selectively adjusting pretrained weights (Problems 2-3)\n",
    "\n",
    "3. **Layer Freezing Technique:** The exercises show how to strategically freeze early layers while making later layers trainable, preserving general features while adapting task-specific ones.\n",
    "\n",
    "4. **Functional API Implementation:** The notebook utilizes Keras's functional API to build complex model architectures with greater flexibility than the Sequential API.\n",
    "\n",
    "5. **Performance Improvement:** Fine-tuning demonstrates improved validation accuracy compared to pure feature extraction, showing how adaptation can enhance transfer learning results.\n",
    "\n",
    "6. **Practical Deep Learning:** The assignment showcases real-world techniques used by practitioners to efficiently apply deep learning to new domains with limited data.\n",
    "\n",
    "These techniques are widely applied in production environments when adapting pretrained models to specific tasks or domains.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codio_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
