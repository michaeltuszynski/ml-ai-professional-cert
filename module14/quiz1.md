## Question 1 (1 pt)
Which of the following statements about decision trees is correct?

1. Decision trees have only one branch.
2. Decision trees are arbitrary and can be answered randomly.
3. Decision trees are used for predictive classification.
4. Decision trees are not suitable for data analysis.

Correct Answer: 3
Explanation: Decision trees are fundamental machine learning algorithms that create a structured, tree-like model for making predictions based on input features. They're widely used in classification tasks and create systematic, interpretable rules.

## Question 2 (1 pt)
Which of the following statements about logistic regression model decision boundaries is correct?

1. Logistic regression decision boundaries are determined by a linear combination of features.
2. Logistic regression decision boundaries are nonparametric.
3. Logistic regression decision boundaries are always linear.
4. Logistic regression decision boundaries are only applicable to binary classification.

Correct Answer: 1
Explanation: Logistic regression uses a linear combination of features to create its decision boundary, though the final output is transformed through the logistic function. It's a parametric model that can handle both binary and multiclass classification.

## Question 3 (1 pt)
Consider the plot with petal_length on the x-axis and petal_width on the y-axis. For a decision rule "petal_width < 0.75 and petal_length < 2" equal to yes, what class would be chosen?

1. none
2. virginica
3. versicolor
4. setosa

Correct Answer: 4
Explanation: Looking at the scatter plot, the rule "petal_width < 0.75 and petal_length < 2" perfectly captures the blue cluster (setosa) in the lower left corner. Only setosa specimens fall within these measurement boundaries, while versicolor and virginica have larger measurements.