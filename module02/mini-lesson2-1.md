# Mini-Lesson 2.1: Machine Learning Statistics Overview

Now that you have had some exposure to the distributions that will be presented in this module, it is time to dig into some machine learning (ML) statistics.

Statistics plays a foundational role in ML. Some key statistical concepts in ML are:

## Descriptive Statistics
This is used to describe and summarize features of a dataset. Measures such as mean, median, mode, variance, and standard deviation fall under this category.

## Inferential Statistics
This is used to make inferences and predictions about a population based on a sample of data. Hypothesis testing, confidence intervals, and regression analysis are examples.

## Probability Theory
Probability concepts are crucial in understanding uncertainty in data and modeling. Bayes' theorem, random variables, and probability distributions are fundamental.

## Sampling
Understanding how to select representative samples from a larger population is key to building accurate models. Techniques such as random sampling and stratified sampling are common.

## Regression Analysis
This is used to model the relationship between a dependent variable and one or more independent variables. Linear regression is a basic form, while more complex forms, such as logistic regression, are used for classification tasks.

## Hypothesis Testing
This is used to determine whether there is enough evidence in a sample of data to infer that a certain condition is true for the entire population.

## Statistical Learning Theory
This branch of statistics deals with the theoretical aspects of how statistical methods perform in terms of their ability to learn from data and make predictions.

---

**Summary**: Statistics provides the framework and tools for understanding data, quantifying uncertainty, and building models in ML. ML often deals with uncertain data, and probability distribution functions (PDFs) play a crucial role in quantifying this uncertainty.