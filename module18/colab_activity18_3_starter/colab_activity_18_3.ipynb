{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colab Activity 18.3: Naive Bayes Algorithm\n",
    "\n",
    "**Expected Time = 60 minutes** \n",
    "\n",
    "\n",
    "This activity focuses on the implementation of the Naive Bayes algorithm.  You will use the Scikit-Learn estimator together with your earlier vectorization strategies to model the WhatsApp text and compare to your earlier work with Logistic Regression.   \n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "- [Problem 5](#-Problem-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-af402ad5c6fd8123",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Small Example\n",
    "\n",
    "\n",
    "The example below is adapted from Marsland's *Machine Learning an Algorithmic Perspective*.  The dataset describes  whether or not a student has a looming deadline, if there is a party going on, and whether or not the student feels lazy.  The activity column is the target, and your aim is to use the Naïve Bayes formula below:\n",
    "\n",
    "$$P(C_i) \\prod_{k} P(X_j^k = a_k | C_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "deadline = ['urgent','urgent','near', 'none', 'none', 'none', 'near', 'near', 'near','urgent']\n",
    "party = ['yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no']\n",
    "lazy = ['yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no']\n",
    "activity = ['party', 'study', 'party', 'party', 'pub', 'party', 'study', 'tv', 'party', 'study']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deadline</th>\n",
       "      <th>party</th>\n",
       "      <th>lazy</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>urgent</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>urgent</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>near</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>none</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>pub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>near</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>near</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>near</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>urgent</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>study</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  deadline party lazy activity\n",
       "0   urgent   yes  yes    party\n",
       "1   urgent    no  yes    study\n",
       "2     near   yes  yes    party\n",
       "3     none   yes   no    party\n",
       "4     none    no  yes      pub\n",
       "5     none   yes   no    party\n",
       "6     near    no   no    study\n",
       "7     near    no  yes       tv\n",
       "8     near   yes  yes    party\n",
       "9   urgent    no   no    study"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'deadline': deadline,\n",
    "                  'party': party,\n",
    "                  'lazy': lazy,\n",
    "                  'activity': activity})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5d1437600c3f2ca4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Here, $C_i$ represents the class in the `activity` columm.  Accordingly, if we want to predict a category of activity given the input: \n",
    "\n",
    "```\n",
    "deadline = near\n",
    "party = no\n",
    "lazy = yes\n",
    "```\n",
    "\n",
    "This means we need four probabilities:\n",
    "\n",
    "- $P(party) \\times P(near | party) \\times P(no party | party) \\times P(lazy | party)$\n",
    "- $P(study) \\times P(near | study) \\times p(noparty | study) \\times P(lazy | study)$\n",
    "- $P(pub) \\times P(near | pub) \\times P(noparty | pub) \\times P(lazy | pub)$\n",
    "- $P(tv) \\times P(near | tv) \\times P(noparty | tv) \\times P(lazy |tv)$\n",
    "\n",
    "Compute these four probabilities and assign them to the list `probs` in the order above (party, study, pub, tv). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9bc8a1669a0b2d75",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.033333333333333326, 0.0, 0.1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "probs = []\n",
    "# Calculate probabilities for each class\n",
    "probs = [\n",
    "    # P(party) × P(near|party) × P(no party|party) × P(lazy|party)\n",
    "    (5/10) * (1/5) * (0/5) * (4/5),\n",
    "\n",
    "    # P(study) × P(near|study) × P(no party|study) × P(lazy|study)\n",
    "    (3/10) * (1/3) * (3/3) * (1/3),\n",
    "\n",
    "    # P(pub) × P(near|pub) × P(no party|pub) × P(lazy|pub)\n",
    "    (1/10) * (0/1) * (1/1) * (1/1),\n",
    "\n",
    "    # P(tv) × P(near|tv) × P(no party|tv) × P(lazy|tv)\n",
    "    (1/10) * (1/1) * (1/1) * (1/1)\n",
    "]\n",
    "\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(probs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c2559e0bf33dc6b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### MAP solution\n",
    "\n",
    "\n",
    "Using these probabilities, the maximum aposteriori solution involves selecting the outcome that is associated with the highest probability.  Use your list of probabilities to identify the `argmax`.  Note you can use `np.argmax` for this or just inspect the values. \n",
    "\n",
    "Assign your answer as a string -- `party`, `study`, `pub`, or `tv` -- to `ans2` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-256e274715d26b4a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ans2 = ''\n",
    "ans2 = 'tv'  # The highest probability from probs\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(ans2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8e4c25d2e63ea3b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Larger Example\n",
    "\n",
    "Now, you are to use the Scikit-Learn vectorizers together with the `MultinomialNB` estimator to implement the Naïve Bayes algorithm for classifying the WhatsApp data.  The data is loaded and split for you below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_df = pd.read_csv('data/Emotion(happy).csv')\n",
    "sad_df = pd.read_csv('data/Emotion(sad).csv.zip', compression = 'zip')\n",
    "full_df = pd.concat([happy_df, sad_df]).reset_index(drop = True)\n",
    "X = full_df.drop('sentiment', axis = 1)\n",
    "y = full_df['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['content'], y, random_state = 42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fe75497137cd1f91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Pipeline with `CountVectorizer`\n",
    "\n",
    "\n",
    "Below, create a pipeline called `cvect_pipe` with named steps `cvect` and `bayes` given by `CountVectorizer()` and `MultinomialNB()`, respectively.\n",
    "\n",
    "Fit this pipeline to the training data `X_train` and `y_train`.\n",
    "\n",
    "Finaly, use the function `score` to evaluate it on the test set `X_test` and `y_test`. Assign the result to `cvect_acc`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6a6f73de4a0f6334",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvect': CountVectorizer(), 'bayes': MultinomialNB()}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvect_pipe = Pipeline([\n",
    "    ('cvect', CountVectorizer()),\n",
    "    ('bayes', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "cvect_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Get accuracy score\n",
    "cvect_acc = cvect_pipe.score(X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "### ANSWER CHECK\n",
    "cvect_pipe.named_steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-58d23432f74f0c60",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Pipeline with `TfidfVectorizer`\n",
    "\n",
    "\n",
    "Below, create a pipeline called `cvect_pipe` with named steps `tfidf` and `bayes` given by `TfidfVectorizer()` and `MultinomialNB()`, respectively.\n",
    "\n",
    "Fit this pipeline to the training data `X_train` and `y_train`.\n",
    "\n",
    "Finaly, use the function `score` to evaluate it on the test set `X_test` and `y_test`. Assign the result to `tfidf_acc`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7b58933a2378e7c8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf': TfidfVectorizer(), 'bayes': MultinomialNB()}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('bayes', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "tfidf_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Get accuracy score\n",
    "tfidf_acc = tfidf_pipe.score(X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### ANSWER CHECK\n",
    "tfidf_pipe.named_steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-317074563a4513fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Assessing performance\n",
    "\n",
    "\n",
    "Now, consider searching the hyperparameters of the model.  Specifically, what is the parameter that controls Laplacian smoothing?  Assign your answer as a string to `ans5` below.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-95a20d96bbe59b77",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ans5 = 'alpha'  # This is the smoothing parameter in MultinomialNB\n",
    "\n",
    "\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(ans5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Exercises\n",
    "\n",
    "This notebook explored the implementation and application of the Naive Bayes algorithm through several key exercises:\n",
    "\n",
    "1. **Basic Naive Bayes Implementation**\n",
    "   - Worked with a small dataset about student activities\n",
    "   - Calculated conditional probabilities manually using the Naive Bayes formula\n",
    "   - Demonstrated Maximum A Posteriori (MAP) decision making\n",
    "\n",
    "2. **Text Classification with Scikit-learn**\n",
    "   - Applied Naive Bayes to WhatsApp messages for sentiment analysis\n",
    "   - Implemented two different text vectorization approaches:\n",
    "     - CountVectorizer pipeline\n",
    "     - TfidfVectorizer pipeline\n",
    "   - Explored Laplacian smoothing via the `alpha` parameter\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. Naive Bayes is effective for text classification due to its:\n",
    "   - Simplicity in probability calculations\n",
    "   - Ability to handle high-dimensional data\n",
    "   - Fast training and prediction times\n",
    "\n",
    "2. Text preprocessing choices matter:\n",
    "   - CountVectorizer provides basic frequency-based features\n",
    "   - TfidfVectorizer adds term importance weighting\n",
    "   \n",
    "3. Laplacian smoothing (controlled by `alpha`) is crucial for:\n",
    "   - Handling unseen features\n",
    "   - Preventing zero probability issues\n",
    "   - Improving model generalization\n",
    "\n",
    "4. Pipeline implementation in scikit-learn:\n",
    "   - Streamlines the text processing workflow\n",
    "   - Combines preprocessing and modeling steps\n",
    "   - Enables easy model evaluation and tuning"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "codio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
